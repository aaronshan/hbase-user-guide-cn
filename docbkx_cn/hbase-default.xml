<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->

<!--
OVERVIEW

The important configs. are listed near the top.  You should change
at least the setting for hbase.tmp.dir.  Other settings will change
dependent on whether you are running hbase in standalone mode or
distributed.  See the hbase reference guide for requirements and
guidance making configuration.

This file does not contain all possible configurations.  The file would be
much larger if it carried everything. The absent configurations will only be
found through source code reading.  The idea is that such configurations are
exotic and only those who would go to the trouble of reading a particular
section in the code would be knowledgeable or invested enough in ever wanting
to alter such configurations, so we do not list them here.  Listing all
possible configurations would overwhelm and obscure the important.
-->

<configuration>

  <!--Configs you will likely change are listed here at the top of the file.
  -->
  <property >
    <name>hbase.tmp.dir</name>
    <value>${java.io.tmpdir}/hbase-${user.name}</value>
    <description>本地文件系统上的临时目录。将'/tmp'改为其他可以持久保存文件的位置，通常能够解决java.io.tmpdir。'/tmp'目录在机器重启后将会被清空。</description>
  </property>
  <property >
    <name>hbase.rootdir</name>
    <value>${hbase.tmp.dir}/hbase</value>
    <description>该目录被region server共享并且用来保存HBase的持久化数据。这个URL应该完全按照文件系统模式的格式来指定。例如，假定使用HDFS目录'/hbase'，并且HDFS的namenode运行在namenode.example.org的9000端口上，那么，该值应该是：
    hdfs://namenode.example.org:9000/hbase。默认情况下，我们也应该将${hbase.tmp.dir}以这种格式进行设置，通常${hbase.tmp.dir}目录的值为/tmp。因此需要该变该值以可以防止数据在机器重启后丢失。</description>
  </property>
  <property >
    <name>hbase.cluster.distributed</name>
    <value>false</value>
    <description>该值指定了集群运行的模式。如果该值为false，表示运行在单机模式，如果该值为true，表示运行在分布式模式。当该值为false时，将会在同一个JVM中启动HBase和Zookeeper的守护进程。</description>
  </property>
  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>localhost</value>
    <description>Zookeeper服务器使用逗号分隔（这个配置项应该被命名为hbase.zookeeper.ensemble）。例如，"host1.mydomain.com,host2.mydomain.com,host3.mydomain.com"。默认该值被设置为localhost以便单机模式和伪分布式模式进行操作。对于完全分布式模式，它应该被设定为Zookeeper服务器的列表。如果hbase-env.sh中设定了HBASE_MANAGES_ZK，那么当集群启动/关闭的时候，也会按照该值启动/关闭Zookeeper。在客户端，我们将确定这个列表的值并且将该值与hbase.zookeeper.clientPort的值组合到一起，然后作为一个字符串参数传递给zookeeper的构造器。</description>
  </property>
  <!--The above are the important configurations for getting hbase up
    and running -->

  <property>
    <name>hbase.local.dir</name>
    <value>${hbase.tmp.dir}/local/</value>
    <description>本地文件系统的目录，用作本地存储。</description>
  </property>

  <!--Master configurations-->
  <property>
    <name>hbase.master.info.port</name>
    <value>16010</value>
    <description>HBase Master的web界面。如果你不想使用web界面，那么将该值设置为-1。</description>
  </property>
  <property>
    <name>hbase.master.info.bindAddress</name>
    <value>0.0.0.0</value>
    <description>HBase Master的web界面的地址。
    </description>
  </property>
  <property>
    <name>hbase.master.logcleaner.plugins</name>
    <value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner</value>
    <description>WAL/HLog清理程序。类名之间以逗号分割，类会被LogsCleaner服务顺序调用，这样就可以删除最早的HLog文件。用户可以实现自己的日志清理程序，只需要在HBase的classpath中加入完整的类名，将上述的日志清理类将hbase-site.xml文件中的默认设置覆盖即可。</description>
  </property>
  <property>
    <name>hbase.master.logcleaner.ttl</name>
    <value>600000</value>
    <description>HLog文件在.oldlogdir目录中最长的生命周期，一旦超过这个值，HLog就会被Master的线程清理掉。</description>
  </property>
  <property>
    <name>hbase.master.hfilecleaner.plugins</name>
    <value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner</value>
    <description>HFile清理程序。类名之间以逗号分割，类会被HFileCleaner服务顺序调用，这样可以删除最早的HFile文件。用户可以实现自己的HFile清理程序，只需要在HBase的classpath中加入完整的类名，将上述的HFile清理类将hbase-site.xml文件中的默认设置覆盖即可。</description>
  </property>
  <property>
    <name>hbase.master.catalog.timeout</name>
    <value>600000(1分钟)</value>
    <description>master监控.META目录的超时时间。</description>
  </property>
  <property>
    <name>hbase.master.infoserver.redirect</name>
    <value>true</value>
    <description>无论Master是否监听了Master的网页UI端口(hbase.master.info.port)，都将请求重定向到Master和RegionServer共享的网页UI服务器。</description>
  </property>

  <!--RegionServer configurations-->
  <property>
    <name>hbase.regionserver.port</name>
    <value>16020</value>
    <description>HBase RegionServer绑定的端口。</description>
  </property>
  <property>
    <name>hbase.regionserver.info.port</name>
    <value>16030</value>
    <description>这是HBase RegionServer的网页UI端口。如果你不想运行RegionServer的网页UI，就将该值设置为-1。
    </description>
  </property>
  <property>
    <name>hbase.regionserver.info.bindAddress</name>
    <value>0.0.0.0</value>
    <description>HBase RegionServer网页UI的绑定地址</description>
  </property>
  <property>
    <name>hbase.regionserver.info.port.auto</name>
    <value>false</value>
    <description>Master或RegionServer是否应该寻找绑定的UI端口。如果hbase.regionserver.info.port已经在使用，就启用自动端口寻找功能。该值在测试时很有用，默认被关闭。</description>
  </property>
  <property>
    <name>hbase.regionserver.handler.count</name>
    <value>30</value>
    <description>在RegionServer上统计RPC监听器实例的数量。同样的属性被master用来统计master处理器的数量。
    </description>
  </property>
  <property>
    <name>hbase.ipc.server.callqueue.handler.factor</name>
    <value>0.1</value>
    <description>用来确定请求队列的数目。值为0表示所有的处理器共享一个队列，值为1表示每一个处理器都拥有自己的队列。</description>
  </property>
<property>
    <name>hbase.ipc.server.callqueue.read.ratio</name>
    <value>0</value>
    <description>将所有的请求队列分为读和写两种队列。指定的间隔（在0.0和1.0之间）将被用来和呼叫队列数相乘。值为0表示没有对呼叫队列进行切分，意味着读和写请求将被放入同一个队列集合中。值小于0.5表示读队列比写队列少。值为0.5表示渡河写队列的数目相同。值超过0.5表示读队列比写队列多。值为1.0表示除了一个队列之外的其他所有队列都用于分派读请求。
      例如，假定请求队列数目为10。
      read.ratio值为0表示：10个队列都包含读/写请求。
      read.ratio值为0.3表示：3个队列只包含读请求，7个队列只包含写请求。
      read.ratio值为0.5表示：5个队列只包含读请求，5个队列只包含写请求。
      read.ratio值为0.8表示：8个队列只包含读请求，2个队列只包含写请求。
      read.ratio值为1表示：9个队列只包含读请求，1个队列只包含写请求。
    </description>
  </property>
  <property>
    <name>hbase.ipc.server.callqueue.scan.ratio</name>
    <value>0</value>
    <description>给定读请求队列的数目。根据总的请求队列乘以callqueue.read.ratio和scan.ratio属性值，来将读请求队列分为短读队列和长读队列。
      值小于0.5表示长读队列比短读队列少。
      值为0.5表示长读队列和短读队列一样多。
      值大于0.5表示长读队列比短读队列多。
      值为1表示对get和scan操作使用相同的队列集合。
      例如：假定读请求队列的数目是8。
      scan.ratio为0或者1表示：8个队列中既包含长读队列也包含短读队列。
        scan.ratio为0.3表示：2个队列只包含长读请求，6个队列只包含短读请求。
        scan.ratio为0.5表示：4个队列只包含长读请求，4个队列只包含短读请求。
        scan.ratio为0.8表示：6个队列只包含长读请求，2个队列只包含短读请求。
    </description>
  </property>
  <property>
    <name>hbase.regionserver.msginterval</name>
    <value>3000(3秒)</value>
    <description>RegionServer和Master之间传递消息的时间间隔，单位是毫秒。</description>
  </property>
  <property>
    <name>hbase.regionserver.regionSplitLimit</name>
    <value>2147483647</value>
    <description>如果在线的region数目超过该值，则不再进行split。该值不是一个硬性限定，但是它会指导regionserver在一个确定的限定值后就不再进行split操作。默认值是MAX_INT。设置为1就可以关闭自动split。</description>
  </property>
  <property>
    <name>hbase.regionserver.logroll.period</name>
    <value>3600000(1小时)</value>
    <description>在这段时期内，所有的日志都会提交到同一个文件中。也就是说，每隔1小时（默认值），就会打开一个新的日志文件。单位是毫秒，默认值是1小时。</description>
  </property>
  <property>
    <name>hbase.regionserver.logroll.errors.tolerated</name>
    <value>2</value>
    <description>日志轮转时，能承受的最大WAL Writer关闭失败次数。值为0时，当日志轮转时如果WAL Writer关闭失败，那么region server就会终止。即使是一个比较小的值(2或者3)也会使得在HDFS错误出现时，region server能有机会将错误修复。</description>
  </property>
  <property>
    <name>hbase.regionserver.hlog.reader.impl</name>
    <value>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader</value>
    <description>HLog file reader 的实现。</description>
  </property>
  <property>
    <name>hbase.regionserver.hlog.writer.impl</name>
    <value>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter</value>
    <description>HLog file writer 的实现。</description>
  </property>
  <property>
    <name>hbase.master.distributed.log.replay</name>
    <value>true</value>
    <description>控制日志的split是在region的reopen前执行还是reopen后执行。如果是true表示在reopen后执行,否则相反。
        'distributed log replay'作为服务器宕机时的默认切分WAL文件的引擎。在hbase 1.0中有新的默认值。为了兼容旧的'分布式日志切分器'，需要将该值设置为false。'Disributed log replay'减少了MTTR(Mean Time To Restoration，平均恢复时间)。因为它不需要写一些中间文件。'DLR'需要将'hfile.format.version'设置为3或者更高。
    </description>
  </property>
  <property>
    <name>hbase.regionserver.global.memstore.size</name>
    <value>0.4</value>
    <description>单个region server的全部memstore的最大值。一旦超过这个值，一个新的更新操作会被挂起，强制执行刷写操作。默认值是堆的40%。直到单个region server上的全部memstore达到了hbase.regionserver.global.memstore.size.lower.limit，被挂起的更新操作和刷写操作会被强制执行。</description>
  </property>
  <property>
    <name>hbase.regionserver.global.memstore.size.lower.limit</name>
    <value>0.95</value>
    <description>在被强制刷写之前，单个region server上的全部memstore所能达到的最大数目。默认值是hbase.regionserver.global.memstore.size的95%。一旦达到100%，即该值与hbase.regionserver.global.memstore.size相等时，更新操作由于memstore限制被阻塞时，系统会以尽可能小的刷写量刷写数据。</description>
  </property>
  <property>
    <name>hbase.regionserver.optionalcacheflushinterval</name>
    <value>3600000(1小时)</value>
    <description>
        一个edit在内存中的最大生存时长，默认3600000毫秒，即1小时。设置为0的话则禁止自动flush。</description>
  </property>
  <property>
    <name>hbase.regionserver.catalog.timeout</name>
    <value>600000(10分钟)</value>
    <description>regionserver的Catalog监控.META.的超时时间。</description>
  </property>
  <property>
    <name>hbase.regionserver.dns.interface</name>
    <value>default</value>
    <description>region server报告自己IP地址的dns接口。</description>
  </property>
  <property>
    <name>hbase.regionserver.dns.nameserver</name>
    <value>default</value>
    <description>region server使用的dns主机名或者IP。</description>
  </property>
  <property>
    <name>hbase.regionserver.region.split.policy</name>
    <value>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy</value>
    <description> 当一个region进行split操作时使用的具体方法。当前可用的split方法有：ConstantSizeRegionSplitPolicy、
        DisabledRegionSplitPolicy、DelimitedKeyPrefixRegionSplitPolicy、KeyPrefixRegionSplitPolicy等。
    </description>
  </property>

  <!--ZooKeeper configuration-->
  <property>
    <name>zookeeper.session.timeout</name>
    <value>90000(90秒)</value>
    <description>ZooKeeper会话超时时间。单位是毫秒。它被用于两种不同的情况。其一，这个值被ZooKeeper客户端在和HBase建立链接时使用。它也被HBase用来启动Zookeeper服务器作为建立绘画的最大超时时间-'maxSessionTimeout'。查看
      http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions。
      例如，如果HBase region server连接被HBase管理的Zookeeper，会话超时时间将会由这个配置项指定。但是连接Zookeeper的region服务器使用和Zookeeper的该配置不同的值来进行链接时，将会使用Zookeeper的该配置的值。因此，尽管可能HBase指定的超时时间是90秒，但是如果Zookeeper指定的时间比90秒更少，那么Zookeeper的配置将会被优先使用。当前Zookeeper的默认值是40秒，比HBase默认的该值要低。
    </description>
  </property>
  <property>
    <name>zookeeper.znode.parent</name>
    <value>/hbase</value>
    <description>HBase在ZooKeeper中的根ZNode。 所有HBase的ZooKeeper文件的路径都使用了在这个node下的相对路径。
      默认情况下，所有HBase的ZooKeeper文件路径都配置成了相对路径。因此，除非被改变，否则它们都会到这个目录下进行操作。
      </description>
  </property>
  <property>
    <name>zookeeper.znode.rootserver</name>
    <value>root-region-server</value>
    <description>保存根region位置的ZNode路径，这个值由master来更新，由客户端和region服务器来读取。如果将其设置为一个相对地址，父目录就是 ${zookeeper.znode.parent}。默认情况下，根region位置的存储路径是/hbase/root-region-server。</description>
  </property>
  <property>
    <name>zookeeper.znode.acl.parent</name>
    <value>acl</value>
    <description>根ZNode的访问控制列表。</description>
  </property>
  <property>
    <name>hbase.zookeeper.dns.interface</name>
    <value>default</value>
    <description>汇报自己IP地址的Zookeeper服务器的网络接口名。</description>
  </property>
  <property>
    <name>hbase.zookeeper.dns.nameserver</name>
    <value>default</value>
    <description>ZooKeeper服务器用来确定正在通信的master的主机名的域名服务器(DNS)的主机名或IP地址。</description>
  </property>
  <!--
  The following three properties are used together to create the list of
  host:peer_port:leader_port quorum servers for ZooKeeper.
  -->
  <property>
    <name>hbase.zookeeper.peerport</name>
    <value>2888</value>
    <description>ZooKeeper服务器之间彼此通信使用的接口。查看http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper
    可以找到更多信息。</description>
  </property>
  <property>
    <name>hbase.zookeeper.leaderport</name>
    <value>3888</value>
    <description>在ZooKeeper领导选举中使用的端口地址。
    查看http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper
    可以找到更多信息。</description>
  </property>
  <!-- End of properties used to generate ZooKeeper host:port quorum list. -->
  <property>
    <name>hbase.zookeeper.useMulti</name>
    <value>false</value>
    <description>Zookeeper支持多重更新功能。它将使Zookeeper操作完成的更快并且能防止一些很难出现的复制失败问题（可以查看 HBASE-2611的作为一个实例）。重要的是：只有在集群中Zookeeper服务器的版本是3.4以上的时候，该值才能被设置为true。Zookeeper在3.4之前的版本不支持多重更新并且如果多重更新被调用会引发故障（查看ZOOKEEPER-1495）。</description>
  </property>
  <property>
    <name>hbase.config.read.zookeeper.config</name>
    <value>false</value>
    <description> 该值为true的时候会允许HBaseConfiguration从zoo.cfg中读ZooKeeper的属性值，默认为false。切换该值为true不被推荐，因为从zoo.cfg中读取ZK的属性已经被废弃了。</description>
  </property>
  <!--
  Beginning of properties that are directly mapped from ZooKeeper's zoo.cfg.
  All properties with an "hbase.zookeeper.property." prefix are converted for
  ZooKeeper's configuration. Hence, if you want to add an option from zoo.cfg,
  e.g.  "initLimit=10" you would append the following to your configuration:
    <property>
      <name>hbase.zookeeper.property.initLimit</name>
      <value>10</value>
    </property>
  -->
  <property>
    <name>hbase.zookeeper.property.initLimit</name>
    <value>10</value>
    <description> ZooKeeper的配置文件zoo.cfg中的属性，表示同步个数限制，默认10个。</description>
  </property>
  <property>
    <name>hbase.zookeeper.property.syncLimit</name>
    <value>5</value>
    <description>ZooKeeper的配置文件zoo.cfg中的属性，表示同步时每次请求和响应的条数，默认是5个。</description>
  </property>
  <property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>${hbase.tmp.dir}/zookeeper</value>
    <description>ZooKeeper的配置文件zoo.cfg中的属性，snapshot存放的目录，默认是${hbase.tmp.dir}/zookeeper。</description>
  </property>
  <property>
    <name>hbase.zookeeper.property.clientPort</name>
    <value>2181</value>
    <description>ZooKeeper的配置文件zoo.cfg中的属性，client连zk的端口，默认2181。</description>
  </property>
  <property>
    <name>hbase.zookeeper.property.maxClientCnxns</name>
    <value>300</value>
    <description>ZooKeeper的配置文件zoo.cfg中的属性，允许接入zk的最大并发连接数的限制，按ip分配，默认300。当HBase运行在单机模式和伪分布式模式时，应该给将该值调高以防止zk连接出现问题。</description>
  </property>
  <!-- End of properties that are directly mapped from ZooKeeper's zoo.cfg -->

  <!--Client configurations-->
  <property>
    <name>hbase.client.write.buffer</name>
    <value>2097152(2*1024*1024字节)</value>
    <description>HTable客户端写缓冲的默认字节大小。该值越大消耗的内存越多 -- 由于服务器端也需要消耗内存来处理传入
        的数据，客户端与服务器端都会消耗更多的内存 -- 较大的缓冲区有助于减少RPC的调用次数。例如，服务器端的消耗大概等于
        hbase.client.write.buffer * hbase.regionserver.handler.count。</description>
  </property>
  <property>
    <name>hbase.client.pause</name>
    <value>100</value>
    <description>通常的客户端暂停时间。最多的用法是客户端在重试前的等待时间。比如失败的get操作和region查询操作等都很可能用到。
    查看hbase.client.retries.number的描述以便了解这个暂停的初始值以及如果写/读仍然失败之后的避退策略。</description>
  </property>
  <property>
    <name>hbase.client.retries.number</name>
    <value>35</value>
    <description>最大重试次数。例如，region查询、get和update操作等发生错误时最大重试次数的值。
        重试的间隔时间为hbase.client.pause。刚开始使用一个初始的时间间隔，如果仍然失败会使用避退的时间间隔。可以查看HConstants#RETRY_BACKOFF来了解具体的避退策略。请根据你的工作负载来设置该值和hbase.client.pause的值。</description>
  </property>
  <property>
    <name>hbase.client.max.total.tasks</name>
    <value>100</value>
    <description>一个HTable实例可以提交给集群的最大并发任务数，默认是100。</description>
  </property>
  <property>
    <name>hbase.client.max.perserver.tasks</name>
    <value>5</value>
    <description>一个HTable实例给一台regionserver提交的最大并发任务数，默认是5。</description>
  </property>
  <property>
    <name>hbase.client.max.perregion.tasks</name>
    <value>1</value>
    <description>客户端并发连接一个region的最大连接数，换句话说，当在region有hbase.client.max.perregion.tasks个写正在处理时，新的Put操作是不会被发送到这个region的，直到该region上的写操作执行完为止，默认是1。</description>
  </property>
  <property>
    <name>hbase.client.scanner.caching</name>
    <value>100</value>
    <description>
        扫描器调用next方法的时候发现本地客户端内存的数据已经取完，就会向服务器端发起请求，该值就是扫描器调用next方法一次性从服务器返回的最大行数。该值越大，扫描器整体的返回速度就越快，但同时依赖的内存也就越多，并且当请求的数据没有在内存命中的话，next方法的返回时间可能会更长，因此要避免这个时间长于扫描器超时的时间。即hbase.client.scanner.timeout.period。</description>
  </property>
  <property>
    <name>hbase.client.keyvalue.maxsize</name>
    <value>10485760(10*1024*1024字节)</value>
    <description>设置KeyValue实例大小的上限，这是为了协助设置存储文件中单个条目存储的上限。这种做法有利于避免region过大但不能被拆分的现象。最好将其设置为最大的region大小。如果用户想绕开这个检查，可以将这个参数设置为0或者更少。</description>
  </property>
  <property>
    <name>hbase.client.scanner.timeout.period</name>
    <value>60000(1分钟)</value>
    <description>客户端扫描器的超时时间，单位是毫秒。</description>
  </property>
  <property>
    <name>hbase.client.localityCheck.threadPoolSize</name>
    <value>2</value>
    <description>做localityCheck的线程池大小，默认是2。</description>
  </property>

  <!--Miscellaneous configuration-->
  <property>
    <name>hbase.bulkload.retries.number</name>
    <value>0</value>
    <description>做bulk load的最大重试次数，默认是0，即代表不断重试。</description>
  </property>
  <property>
    <name>hbase.balancer.period
    </name>
    <value>300000(5分钟)</value>
    <description>在Master节点中运行region负载均衡器的周期。</description>
  </property>
  <property>
    <name>hbase.balancer.backupMasterWeight</name>
    <value>1</value>
    <description>用来控制相对于普通的region server，region均衡器能分配给多少个region给备份Master。默认值为1代表着备份Master能拥有和普通region server一样多的region。权重越大，备份Master将持有的region数就越少。如果该权重小于1，那么均衡器将不会分配region给备份Master。</description>
  </property>
  <property>
    <name>hbase.regions.slop</name>
    <value>0.2</value>
    <description>
        如果有regionserver的region数目超过average + (average * slop)，则重新balance，默认是0.2。</description>
  </property>
  <property>
    <name>hbase.server.thread.wakefrequency</name>
    <value>10000</value>
    <description>
        两次查询工作的间隔时间，单位为毫秒。通常被用作像log roller这样的服务线程的休息间隔时间。</description>
  </property>
  <property>
    <name>hbase.server.versionfile.writeattempts</name>
    <value>3</value>
    <description>
        退出前写version file文件的重试次数，默认值是3，每次尝试的间隔由参数hbase.server.thread.wakefrequency控制。</description>
  </property>
  <property>
    <name>hbase.hregion.memstore.flush.size</name>
    <value>134217728(128*1024*1024字节)</value>
    <description>
    如果Memstore的大小超过这个值，Memstore的数据就会刷写到磁盘中。这个值由一个线程每隔hbase.server.thread.wakefrequency检查一次。</description>
  </property>
  <property>
    <name>hbase.hregion.preclose.flush.size</name>
    <value>5242880</value>
    <description>
      当我们要关闭一个region，而该region的memstore的大小大于这个值，那么就会先运行“预刷写”操作，清理这个需要关闭的memstore，然后再将这个region下线。在关闭region时，关闭标签会触发一次清空内存的刷写。在region处于下线过程中时，我们就无法再对其进行任何写操作了。如果一个memstore的内容很大，刷写磁盘的操作就会消耗很多时间。预刷写操作意味着在region被打上关闭标签之前，会先把memstore清空。这样在最终执行关闭操作的时候，带关闭操作的刷写速度会很快。</description>
  </property>
  <property>
    <name>hbase.hregion.memstore.block.multiplier</name>
    <value>4</value>
    <description>
    如果memstore达到了hbase.hregion.memstore.block.multiplier
    乘以hbase.hregion.memstore.flush.size的大小，就会阻塞更新操作。这是为了预防在更新高峰期或导致的失控。如果不设上界，刷写的时候会花费很长的时间来合并或者拆分，最坏的情况会引发OOME异常。</description>
  </property>
  <property>
    <name>hbase.hregion.memstore.mslab.enabled</name>
    <value>true</value>
    <description>
      启动本地MemStore分配缓冲区(MemStore-Local Allocation Buffer)，这个特性是为了防止在大量写负载的时候堆的碎片太多。这将降低大堆中垃圾回收的频率。</description>
  </property>
  <property>
    <name>hbase.hregion.max.filesize</name>
    <value>10737418240 (10*1024*1024*1024字节)</value>
    <description>
    HFile的最大大小。如果一个region的HFile总的大小超过了这个上线，那么它会被拆分为两个region。</description>
  </property>
  <property>
    <name>hbase.hregion.majorcompaction</name>
    <value>604800000(7天)</value>
    <description>两次major合并的间隔时间，单位是毫秒。默认值是7天。将其设置为0可以禁用major合并。当用户请求major合并或者满足major合并要求时将会进行。该值乘以hbase.hregion.majorcompaction.jitter的值以便在一个给定的时间窗口期间的一个随机时间来开启major合并操作。major合并可能会导致集群无法访问，你可以在你的配置中将它设置为在低峰时段运行，或者通过将它设置为0而禁用它，或者通过另外一种额外的机制来定时运行major合并操作。</description>
  </property>
  <property>
    <name>hbase.hregion.majorcompaction.jitter</name>
    <value>0.50</value>
    <description>
        合并的时间不仅仅是由hbase.hregion.majorcompaction指定的，也就是说，hbase.hregion.majorcompaction并不是一个严格的时间。合并时间是存在抖动的。这个参数就是这个抖动的比例。假如该值和hbase.hregion.majorcompaction都使用默认值，则最终的合并时间在（7-7*0.5）~（7+7*0.5）之间。所以该值越小，合并的时间就会越接近hbase.hregion.majorcompaction指定的时间。</description>
  </property>
  <property>
    <name>hbase.hstore.compactionThreshold</name>
    <value>3</value>
    <description> 如果在一个Store（一个MemStore的一次刷写将产生一个一个StoreFile文件）中的StoreFile文件超过了该值，那么将会产生将会产生一个合并操作，该操作将多个StoreFile文件合并成一个StoreFile。该值越大意味着合并操作会延迟，但是当合并发生的时候，也会花费更长的时间。</description>
  </property>
  <property>
    <name>hbase.hstore.flusher.count</name>
    <value>2</value>
    <description>刷写线程的数量。线程数越少，MemStore的刷写操作将会被排成队列。线程数越多，刷写将会并行执行，也将会增加HDFS的负载，并且也可能会引发更多的合并操作。</description>
  </property>
  <property>
    <name>hbase.hstore.blockingStoreFiles</name>
    <value>10</value>
    <description> 如果一个Store中StoreFile文件的数目（每次MemStore刷写到磁盘都会产生一个StoreFile文件）大于这个阈值，那么对这个region的更新操作就会被阻塞，直到合并操作完成或者一直阻塞到超过hbase.hstore.blockingWaitTime。</description>
  </property>
  <property>
    <name>hbase.hstore.blockingWaitTime</name>
    <value>90000</value>
    <description> 一个region的StoreFile数目达到了hbase.hstore.blockingStoreFiles设置的值后，它会阻塞对其他客户端的更新请求。超过当前设定的时间之后，即使合并没有完成，也会停止对更新操作的阻塞。</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.min</name>
    <value>3</value>
    <description>可以进行合并的StoreFile在一次合时并必须满足的最小的StoreFile数目。设置hbase.hstore.compaction.min的值是为了防止太多的小的StoreFile被合并。将该值设置为2将会导致一次minor合并每次只能合并2个StoreFile，并且这样可能不太恰当。如果你将该值设定的过大，其他的值也需要被适当的调整。大多数情况下，默认值是适当的。在之前的HBase版本中，hbase.hstore.compaction.min被称为hbase.hstore.compactionThreshold。</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.max</name>
    <value>10</value>
    <description>每次minor合并所要处理的最大的StoreFile数目，无论需要合并的数目是多少。hbase.hstore.compaction.max的值控制着单次合并完成所要花费的时间。将这个值设定的更大意味着一次合并将包括更多的StoreFile文件。大多数情况下，默认值是适当的。</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.min.size</name>
    <value>134217728(128*1024*1024字节)</value>
    <description>
        StoreFile文件的大小如果小于该值，那在minor合并的时候，肯定会将该文件加入。会通过hbase.hstore.compaction.ratio来评估故HFile的大小，看它们在minor合并时是否应该被加入。因为该值代表着所有如果小于该值的StoreFile会被“自动加入”。如果在频繁写的环境中，刷写操作可能会产生很多大小在1~2MB的StoreFile文件，那么该值就应该被适当减小。因为这些小文件在合并之后很可能会继续触发合并操作。如果该值减小，合并的触发检查也会更加迅速。在早期的HBase版本中，如果该参数不设置可能会有一些问题。但是现在的大多数环境下，已经不再需要改变该参数了。该参数默认值是：128MB。
      </description>
  </property>
    <property>
    <name>hbase.hstore.compaction.max.size</name>
    <value>9223372036854775807</value>
    <description>如果一个StoreFile的大小比该值还大，那么当合并发生时，该StoreFile就会被排除在外。
        A StoreFile larger than this size will be excluded from compaction. The effect of
      raising hbase.hstore.compaction.max.size is fewer, larger StoreFiles that do not get 
      compacted often. If you feel that compaction is happening too often without much benefit, you
      can try raising this value. Default: the value of LONG.MAX_VALUE, expressed in bytes.</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.ratio</name>
    <value>1.2F</value>
    <description>For minor compaction, this ratio is used to determine whether a given StoreFile 
      which is larger than hbase.hstore.compaction.min.size is eligible for compaction. Its
      effect is to limit compaction of large StoreFiles. The value of hbase.hstore.compaction.ratio
      is expressed as a floating-point decimal. A large ratio, such as 10, will produce a single 
      giant StoreFile. Conversely, a low value, such as .25, will produce behavior similar to the 
      BigTable compaction algorithm, producing four StoreFiles. A moderate value of between 1.0 and
      1.4 is recommended. When tuning this value, you are balancing write costs with read costs. 
      Raising the value (to something like 1.4) will have more write costs, because you will 
      compact larger StoreFiles. However, during reads, HBase will need to seek through fewer 
      StoreFiles to accomplish the read. Consider this approach if you cannot take advantage of 
      Bloom filters. Otherwise, you can lower this value to something like 1.0 to reduce the 
      background cost of writes, and use Bloom filters to control the number of StoreFiles touched 
      during reads. For most cases, the default value is appropriate.</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.ratio.offpeak</name>
    <value>5.0F</value>
    <description>Allows you to set a different (by default, more aggressive) ratio for determining
      whether larger StoreFiles are included in compactions during off-peak hours. Works in the 
      same way as hbase.hstore.compaction.ratio. Only applies if hbase.offpeak.start.hour and 
      hbase.offpeak.end.hour are also enabled.</description>
  </property>
  <property>
    <name>hbase.hstore.time.to.purge.deletes</name>
    <value>0</value>
    <description>The amount of time to delay purging of delete markers with future timestamps. If 
      unset, or set to 0, all delete markers, including those with future timestamps, are purged 
      during the next major compaction. Otherwise, a delete marker is kept until the major compaction 
      which occurs after the marker's timestamp plus the value of this setting, in milliseconds.
    </description>
  </property>
  <property>
    <name>hbase.offpeak.start.hour</name>
    <value>-1</value>
    <description>The start of off-peak hours, expressed as an integer between 0 and 23, inclusive.
      Set to -1 to disable off-peak.</description>
  </property>
  <property>
    <name>hbase.offpeak.end.hour</name>
    <value>-1</value>
    <description>The end of off-peak hours, expressed as an integer between 0 and 23, inclusive. Set
      to -1 to disable off-peak.</description>
  </property>
  <property>
    <name>hbase.regionserver.thread.compaction.throttle</name>
    <value>2560</value>
    <description>There are two different thread pools for compactions, one for large compactions and
      the other for small compactions. This helps to keep compaction of lean tables (such as
        <systemitem>hbase:meta</systemitem>) fast. If a compaction is larger than this threshold, it
      goes into the large compaction pool. In most cases, the default value is appropriate. Default:
      2 x hbase.hstore.compaction.max x hbase.hregion.memstore.flush.size (which defaults to 128).
      The value field assumes that the value of hbase.hregion.memstore.flush.size is unchanged from
      the default.</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.kv.max</name>
    <value>10</value>
    <description>The maximum number of KeyValues to read and then write in a batch when flushing or
      compacting. Set this lower if you have big KeyValues and problems with Out Of Memory
      Exceptions Set this higher if you have wide, small rows. </description>
  </property>
  <property>
    <name>hbase.storescanner.parallel.seek.enable</name>
    <value>false</value>
    <description>
      Enables StoreFileScanner parallel-seeking in StoreScanner,
      a feature which can reduce response latency under special conditions.</description>
  </property>
  <property>
    <name>hbase.storescanner.parallel.seek.threads</name>
    <value>10</value>
    <description>
      The default thread pool size if parallel-seeking feature enabled.</description>
  </property>
  <property>
    <name>hfile.block.cache.size</name>
    <value>0.4</value>
    <description>Percentage of maximum heap (-Xmx setting) to allocate to block cache
        used by a StoreFile. Default of 0.4 means allocate 40%.
        Set to 0 to disable but it's not recommended; you need at least
        enough cache to hold the storefile indices.</description>
  </property>
  <property>
      <name>hfile.block.index.cacheonwrite</name>
      <value>false</value>
      <description>This allows to put non-root multi-level index blocks into the block
          cache at the time the index is being written.</description>
  </property>
  <property>
      <name>hfile.index.block.max.size</name>
      <value>131072</value>
      <description>When the size of a leaf-level, intermediate-level, or root-level
          index block in a multi-level block index grows to this size, the
          block is written out and a new block is started.</description>
  </property>
  <property>
      <name>hfile.format.version</name>
      <value>3</value>
      <description>The HFile format version to use for new files.
      Version 3 adds support for tags in hfiles (See http://hbase.apache.org/book.html#hbase.tags).
      Distributed Log Replay requires that tags are enabled.
      </description>
  </property>
  <property>
      <name>hfile.block.bloom.cacheonwrite</name>
      <value>false</value>
      <description>Enables cache-on-write for inline blocks of a compound Bloom filter.</description>
  </property>
  <property>
      <name>io.storefile.bloom.block.size</name>
      <value>131072</value>
      <description>The size in bytes of a single block ("chunk") of a compound Bloom
          filter. This size is approximate, because Bloom blocks can only be
          inserted at data block boundaries, and the number of keys per data
          block varies.</description>
  </property>
  <property>
      <name>hbase.rs.cacheblocksonwrite</name>
      <value>false</value>
      <description>Whether an HFile block should be added to the block cache when the
          block is finished.</description>
  </property>
  <property>
    <name>hbase.rpc.server.engine</name>
    <value>org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine</value>
    <description>Implementation of org.apache.hadoop.hbase.ipc.RpcServerEngine to be
    used for server RPC call marshalling.</description>
  </property>
  <property>
    <name>hbase.rpc.timeout</name>
    <value>60000</value>
    <description>This is for the RPC layer to define how long HBase client applications
        take for a remote call to time out. It uses pings to check connections
        but will eventually throw a TimeoutException.</description>
  </property>
  <property>
    <name>hbase.rpc.shortoperation.timeout</name>
    <value>10000</value>
    <description>This is another version of "hbase.rpc.timeout". For those RPC operation
        within cluster, we rely on this configuration to set a short timeout limitation
        for short operation. For example, short rpc timeout for region server's trying
        to report to active master can benefit quicker master failover process.</description>
  </property>
  <property>
    <name>hbase.ipc.client.tcpnodelay</name>
    <value>true</value>
    <description>Set no delay on rpc socket connections.  See
    http://docs.oracle.com/javase/1.5.0/docs/api/java/net/Socket.html#getTcpNoDelay()</description>
  </property>
  <!-- The following properties configure authentication information for
       HBase processes when using Kerberos security.  There are no default
       values, included here for documentation purposes -->
  <property>
    <name>hbase.master.keytab.file</name>
    <value></value>
    <description>用于登录配置的HMaster服务器实体(HMaster server principal)的kerberos keytab文件的完整路径。</description>
  </property>
  <property>
    <name>hbase.master.kerberos.principal</name>
    <value></value>
    <description>例如， "hbase/_HOST@EXAMPLE.COM"。HMaster进程运行时需要使用kerberos实体(kerberos principal)，实体可以使用这种格式：user/hostname@DOMAIN。
        如果"_HOST"部分使用主机名，它在实际运行的时候将使用主机名来替代。</description>
  </property>
  <property>
    <name>hbase.regionserver.keytab.file</name>
    <value></value>
    <description>用于登录配置的HRegionServer服务器实体(HRegionServer server principal)的kerberos keytab文件的完整路径。</description>
  </property>
  <property>
    <name>hbase.regionserver.kerberos.principal</name>
    <value></value>
    <description>例如， "hbase/_HOST@EXAMPLE.COM"。HRegionServer进程运行时需要使用kerberos实体(kerberos principal)，实体可以使用这种格式：user/hostname@DOMAIN。
        如果"_HOST"部分使用主机名，它在实际运行的时候将使用主机名来替代。这个实体的入口必须在hbase.regionserver.keytab.file文件中指定。</description>
  </property>
  <!-- Additional configuration specific to HBase security -->
  <property>
    <name>hadoop.policy.file</name>
    <value>hbase-policy.xml</value>
    <description>The policy configuration file used by RPC servers to make
      authorization decisions on client requests.  Only used when HBase
      security is enabled.</description>
  </property>
  <property>
    <name>hbase.superuser</name>
    <value></value>
    <description>List of users or groups (comma-separated), who are allowed
    full privileges, regardless of stored ACLs, across the cluster.
    Only used when HBase security is enabled.</description>
  </property>
  <property>
    <name>hbase.auth.key.update.interval</name>
    <value>86400000</value>
    <description>The update interval for master key for authentication tokens
    in servers in milliseconds.  Only used when HBase security is enabled.</description>
  </property>
  <property>
    <name>hbase.auth.token.max.lifetime</name>
    <value>604800000</value>
    <description>The maximum lifetime in milliseconds after which an
    authentication token expires.  Only used when HBase security is enabled.</description>
  </property>
  <property>
    <name>hbase.ipc.client.fallback-to-simple-auth-allowed</name>
    <value>false</value>
    <description>When a client is configured to attempt a secure connection, but attempts to
      connect to an insecure server, that server may instruct the client to
      switch to SASL SIMPLE (unsecure) authentication. This setting controls
      whether or not the client will accept this instruction from the server.
      When false (the default), the client will not allow the fallback to SIMPLE
      authentication, and will abort the connection.</description>
  </property>
  <property>
    <name>hbase.display.keys</name>
    <value>true</value>
    <description>When this is set to true the webUI and such will display all start/end keys
                 as part of the table details, region names, etc. When this is set to false,
                 the keys are hidden.</description>
  </property>
  <property>
    <name>hbase.coprocessor.region.classes</name>
    <value></value>
    <description>协处理器之间使用逗号分隔，这些协处理器默认会被所有的表加载。用户可以实现自己的协处理器，只需将其添加到HBase的classpath中，并在此配置完整类名。用户也可以根据需求设置HTableDescriptor来选择性的加载协处理器。</description>
  </property>
  <property>
    <name>hbase.rest.port</name>
    <value>8080</value>
    <description>The port for the HBase REST server.</description>
  </property>
  <property>
    <name>hbase.rest.readonly</name>
    <value>false</value>
    <description>Defines the mode the REST server will be started in. Possible values are:
    false: All HTTP methods are permitted - GET/PUT/POST/DELETE.
    true: Only the GET method is permitted.</description>
  </property>
  <property>
    <name>hbase.rest.threads.max</name>
    <value>100</value>
    <description>The maximum number of threads of the REST server thread pool.
        Threads in the pool are reused to process REST requests. This
        controls the maximum number of requests processed concurrently.
        It may help to control the memory used by the REST server to
        avoid OOM issues. If the thread pool is full, incoming requests
        will be queued up and wait for some free threads.</description>
  </property>
  <property>
    <name>hbase.rest.threads.min</name>
    <value>2</value>
    <description>The minimum number of threads of the REST server thread pool.
        The thread pool always has at least these number of threads so
        the REST server is ready to serve incoming requests.</description>
  </property>
  <property>
    <name>hbase.rest.support.proxyuser</name>
    <value>false</value>
    <description>Enables running the REST server to support proxy-user mode.</description>
  </property>
  <property skipInDoc="true">
    <name>hbase.defaults.for.version</name>
    <value>@@@VERSION@@@</value>
    <description>默认值是是被编译的${project.version}的版本号。这个值用来确定用户在classpath中没有一个旧版本的hbase-default.xml。</description>
  </property>
  <property>
    <name>hbase.defaults.for.version.skip</name>
    <value>false</value>
    <description>将当前参数设置为true可以跳过'hbase.defaults.for.version'检查。将该参数设置为true，它会在上下文中发挥作用。这一点不同于它在maven下的使用方法，即在IDE中通过maven使用HBase。用户也可以将该参数设置为true，以避免因为hbase-default.xml中的版本检查通不过而产生的运行时异常："hbase-default.xml file
    seems to be for and old version of HBase (\${hbase.version}), this
    version is X.X.X-SNAPSHOT"。</description>
  </property>
  <property>
    <name>hbase.coprocessor.master.classes</name>
    <value></value>
    <description>HMaster进程默认使用的协处理器是org.apache.hadoop.hbase.coprocessor.MasterObserver，在该配置中，协处理器之间使用逗号分隔，协处理器中实现的方法将按照配置顺序执行。用户可以通过继承MasterObserver来实现自己的协处理器，只需要将其添加到classpath，并添加可用的类名。</description>
  </property>
  <property>
      <name>hbase.coprocessor.abortonerror</name>
      <value>true</value>
      <description>Set to true to cause the hosting server (master or regionserver)
      to abort if a coprocessor fails to load, fails to initialize, or throws an
      unexpected Throwable object. Setting this to false will allow the server to
      continue execution but the system wide state of the coprocessor in question
      will become inconsistent as it will be properly executing in only a subset
      of servers, so this is most useful for debugging only.</description>
  </property>
  <property>
    <name>hbase.online.schema.update.enable</name>
    <value>true</value>
    <description>Set true to enable online schema changes.</description>
  </property>
  <property>
    <name>hbase.table.lock.enable</name>
    <value>true</value>
    <description>Set to true to enable locking the table in zookeeper for schema change operations.
    Table locking from master prevents concurrent schema modifications to corrupt table
    state.</description>
  </property>
  <property>
    <name>hbase.table.max.rowsize</name>
    <value>1073741824</value>
    <description>
      Maximum size of single row in bytes (default is 1 Gb) for Get'ting
      or Scan'ning without in-row scan flag set. If row size exceeds this limit
      RowTooBigException is thrown to client.
    </description>
  </property>
  <property>
    <name>hbase.thrift.minWorkerThreads</name>
    <value>16</value>
    <description>The "core size" of the thread pool. New threads are created on every
    connection until this many threads are created.</description>
  </property>
  <property>
    <name>hbase.thrift.maxWorkerThreads</name>
    <value>1000</value>
    <description>The maximum size of the thread pool. When the pending request queue
    overflows, new threads are created until their number reaches this number.
    After that, the server starts dropping connections.</description>
  </property>
  <property>
    <name>hbase.thrift.maxQueuedRequests</name>
    <value>1000</value>
    <description>The maximum number of pending Thrift connections waiting in the queue. If
     there are no idle threads in the pool, the server queues requests. Only
     when the queue overflows, new threads are added, up to
     hbase.thrift.maxQueuedRequests threads.</description>
  </property>
  <property>
    <name>hbase.thrift.htablepool.size.max</name>
    <value>1000</value>
    <description>The upper bound for the table pool used in the Thrift gateways server.
      Since this is per table name, we assume a single table and so with 1000 default
      worker threads max this is set to a matching number. For other workloads this number
      can be adjusted as needed.
    </description>
  </property>
  <property>
    <name>hbase.regionserver.thrift.framed</name>
    <value>false</value>
    <description>Use Thrift TFramedTransport on the server side.
      This is the recommended transport for thrift servers and requires a similar setting
      on the client side. Changing this to false will select the default transport,
      vulnerable to DoS when malformed requests are issued due to THRIFT-601.
    </description>
  </property>
  <property>
   <name>hbase.regionserver.thrift.framed.max_frame_size_in_mb</name>
    <value>2</value>
    <description>Default frame size when using framed transport</description>
  </property>
  <property>
    <name>hbase.regionserver.thrift.compact</name>
    <value>false</value>
    <description>Use Thrift TCompactProtocol binary serialization protocol.</description>
  </property>
  <property>
    <name>hbase.data.umask.enable</name>
    <value>false</value>
    <description>Enable, if true, that file permissions should be assigned
      to the files written by the regionserver</description>
  </property>
  <property>
    <name>hbase.data.umask</name>
    <value>000</value>
    <description>File permissions that should be used to write data
      files when hbase.data.umask.enable is true</description>
  </property>
  <property>
    <name>hbase.metrics.showTableName</name>
    <value>true</value>
    <description>Whether to include the prefix "tbl.tablename" in per-column family metrics.
	If true, for each metric M, per-cf metrics will be reported for tbl.T.cf.CF.M, if false,
	per-cf metrics will be aggregated by column-family across tables, and reported for cf.CF.M.
	In both cases, the aggregated metric M across tables and cfs will be reported.</description>
  </property>
  <property>
    <name>hbase.metrics.exposeOperationTimes</name>
    <value>true</value>
    <description>Whether to report metrics about time taken performing an
      operation on the region server.  Get, Put, Delete, Increment, and Append can all
      have their times exposed through Hadoop metrics per CF and per region.</description>
  </property>
  <property>
    <name>hbase.snapshot.enabled</name>
    <value>true</value>
    <description>Set to true to allow snapshots to be taken / restored / cloned.</description>
  </property>
  <property>
    <name>hbase.snapshot.restore.take.failsafe.snapshot</name>
    <value>true</value>
    <description>Set to true to take a snapshot before the restore operation.
      The snapshot taken will be used in case of failure, to restore the previous state.
      At the end of the restore operation this snapshot will be deleted</description>
  </property>
  <property>
    <name>hbase.snapshot.restore.failsafe.name</name>
    <value>hbase-failsafe-{snapshot.name}-{restore.timestamp}</value>
    <description>Name of the failsafe snapshot taken by the restore operation.
      You can use the {snapshot.name}, {table.name} and {restore.timestamp} variables
      to create a name based on what you are restoring.</description>
  </property>
  <property>
    <name>hbase.server.compactchecker.interval.multiplier</name>
    <value>1000</value>
    <description>The number that determines how often we scan to see if compaction is necessary.
        Normally, compactions are done after some events (such as memstore flush), but if
        region didn't receive a lot of writes for some time, or due to different compaction
        policies, it may be necessary to check it periodically. The interval between checks is
        hbase.server.compactchecker.interval.multiplier multiplied by
        hbase.server.thread.wakefrequency.</description>
  </property>
  <property>
    <name>hbase.lease.recovery.timeout</name>
    <value>900000</value>
    <description>How long we wait on dfs lease recovery in total before giving up.</description>
  </property>
  <property>
    <name>hbase.lease.recovery.dfs.timeout</name>
    <value>64000</value>
    <description>How long between dfs recover lease invocations. Should be larger than the sum of
        the time it takes for the namenode to issue a block recovery command as part of
        datanode; dfs.heartbeat.interval and the time it takes for the primary
        datanode, performing block recovery to timeout on a dead datanode; usually
        dfs.client.socket-timeout. See the end of HBASE-8389 for more.</description>
  </property>
  <property>
    <name>hbase.column.max.version</name>
    <value>1</value>
    <description>New column family descriptors will use this value as the default number of versions
      to keep.</description>
  </property>
  <property>
    <name>hbase.dfs.client.read.shortcircuit.buffer.size</name>
    <value>131072</value>
    <description>If the DFSClient configuration
    dfs.client.read.shortcircuit.buffer.size is unset, we will
    use what is configured here as the short circuit read default
    direct byte buffer size. DFSClient native default is 1MB; HBase
    keeps its HDFS files open so number of file blocks * 1MB soon
    starts to add up and threaten OOME because of a shortage of
    direct memory.  So, we set it down from the default.  Make
    it > the default hbase block size set in the HColumnDescriptor
    which is usually 64k.
    </description>
  </property>
  <property>
    <name>hbase.regionserver.checksum.verify</name>
    <value>true</value>
    <description>
        If set to true (the default), HBase verifies the checksums for hfile
        blocks. HBase writes checksums inline with the data when it writes out
        hfiles. HDFS (as of this writing) writes checksums to a separate file
        than the data file necessitating extra seeks.  Setting this flag saves
        some on i/o.  Checksum verification by HDFS will be internally disabled
        on hfile streams when this flag is set.  If the hbase-checksum verification
        fails, we will switch back to using HDFS checksums (so do not disable HDFS
        checksums!  And besides this feature applies to hfiles only, not to WALs).
        If this parameter is set to false, then hbase will not verify any checksums,
        instead it will depend on checksum verification being done in the HDFS client.  
    </description>
  </property>
  <property>
    <name>hbase.hstore.bytes.per.checksum</name>
    <value>16384</value>
    <description>
        Number of bytes in a newly created checksum chunk for HBase-level
        checksums in hfile blocks.
    </description>
  </property>
  <property>
    <name>hbase.hstore.checksum.algorithm</name>
    <value>CRC32</value>
    <description>
      Name of an algorithm that is used to compute checksums. Possible values
      are NULL, CRC32, CRC32C.
    </description>
  </property>

  <property>
    <name>hbase.status.published</name>
    <value>false</value>
    <description>
      This setting activates the publication by the master of the status of the region server.
      When a region server dies and its recovery starts, the master will push this information
      to the client application, to let them cut the connection immediately instead of waiting
      for a timeout.
    </description>
  </property>
  <property>
    <name>hbase.status.publisher.class</name>
    <value>org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher</value>
    <description>
      Implementation of the status publication with a multicast message.
    </description>
  </property>
  <property>
    <name>hbase.status.listener.class</name>
    <value>org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener</value>
    <description>
      Implementation of the status listener with a multicast message.
    </description>
  </property>
  <property>
    <name>hbase.status.multicast.address.ip</name>
    <value>226.1.1.3</value>
    <description>
      Multicast address to use for the status publication by multicast.
    </description>
  </property>
  <property>
    <name>hbase.status.multicast.address.port</name>
    <value>16100</value>
    <description>
      Multicast port to use for the status publication by multicast.
    </description>
  </property>

  <property>
    <name>hbase.dynamic.jars.dir</name>
    <value>${hbase.rootdir}/lib</value>
    <description>
      The directory from which the custom filter/co-processor jars can be loaded
      dynamically by the region server without the need to restart. However,
      an already loaded filter/co-processor class would not be un-loaded. See
      HBASE-1936 for more details.
    </description>
  </property>
  <property>
    <name>hbase.security.authentication</name>
    <value>simple</value>
    <description>
      Controls whether or not secure authentication is enabled for HBase.
      Possible values are 'simple' (no authentication), and 'kerberos'.
    </description>
  </property>
  <property>
    <name>hbase.rest.filter.classes</name>
    <value>org.apache.hadoop.hbase.rest.filter.GzipFilter</value>
    <description>
      Servlet filters for REST service.
    </description>
  </property>
  <property>
    <name>hbase.master.loadbalancer.class</name>
    <value>org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer</value>
    <description>
      Class used to execute the regions balancing when the period occurs.
      See the class comment for more on how it works
      http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.html
      It replaces the DefaultLoadBalancer as the default (since renamed
      as the SimpleLoadBalancer).
    </description>
  </property>
  <property>
    <name>hbase.security.exec.permission.checks</name>
    <value>false</value>
    <description>
      If this setting is enabled and ACL based access control is active (the
      AccessController coprocessor is installed either as a system coprocessor
      or on a table as a table coprocessor) then you must grant all relevant
      users EXEC privilege if they require the ability to execute coprocessor
      endpoint calls. EXEC privilege, like any other permission, can be
      granted globally to a user, or to a user on a per table or per namespace
      basis. For more information on coprocessor endpoints, see the coprocessor
      section of the HBase online manual. For more information on granting or
      revoking permissions using the AccessController, see the security
      section of the HBase online manual.
    </description>
  </property>
  <property>
    <name>hbase.procedure.regionserver.classes</name>
    <value></value>
    <description>A comma-separated list of 
    org.apache.hadoop.hbase.procedure.RegionServerProcedureManager procedure managers that are 
    loaded by default on the active HRegionServer process. The lifecycle methods (init/start/stop) 
    will be called by the active HRegionServer process to perform the specific globally barriered 
    procedure. After implementing your own RegionServerProcedureManager, just put it in 
    HBase's classpath and add the fully qualified class name here.
    </description>
  </property>
    <property>
    <name>hbase.procedure.master.classes</name>
    <value></value>
    <description>A comma-separated list of
    org.apache.hadoop.hbase.procedure.MasterProcedureManager procedure managers that are
    loaded by default on the active HMaster process. A procedure is identified by its signature and
    users can use the signature and an instant name to trigger an execution of a globally barriered
    procedure. After implementing your own MasterProcedureManager, just put it in HBase's classpath
    and add the fully qualified class name here.</description>
  </property>
  <property>
    <name>hbase.coordinated.state.manager.class</name>
    <value>org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager</value>
    <description>Fully qualified name of class implementing coordinated state manager.</description>
  </property>
  <property>
    <name>hbase.regionserver.storefile.refresh.period</name>
    <value>0</value>
    <description>
      The period (in milliseconds) for refreshing the store files for the secondary regions. 0
      means this feature is disabled. Secondary regions sees new files (from flushes and
      compactions) from primary once the secondary region refreshes the list of files in the
      region (there is no notification mechanism). But too frequent refreshes might cause
      extra Namenode pressure. If the files cannot be refreshed for longer than HFile TTL
      (hbase.master.hfilecleaner.ttl) the requests are rejected. Configuring HFile TTL to a larger
      value is also recommended with this setting.
    </description>
  </property>
  <property>
    <name>hbase.http.filter.initializers</name>
    <value>org.apache.hadoop.hbase.http.lib.StaticUserWebFilter</value>
    <description>
      类名使用逗号分割。其中的每一个类都继承自org.apache.hadoop.hbase.http.FilterInitializer。相应的过滤器将会被初始化。紧接着，过滤器在所有用户访问jsp和servlet网页的时候使用。过滤器按照定义的顺序依次使用。默认的StaticUserWebFilter过滤器会增加一个在hbase.http.staticuser.user中定义的用户。
    </description>
  </property>
    <property>
    <name>hbase.security.visibility.mutations.checkauths</name>
    <value>false</value>
    <description>
      该属性如果启用，将会检查可见表达式中的标签是否与用户发出的行为相关联。
    </description>
  </property>
  <property>
    <name>hbase.http.max.threads</name>
    <value>10</value>
    <description>
      HTTP服务器创建的线程池中线程的最大数目。
    </description>
  </property>
  <!-- Static Web User Filter properties. -->
  <property>
    <description>
      n用户名过滤器。当在静态网页上呈现内容时的过滤器。一个使用的例子是HDFS的网页UI（用于浏览文件的用户）。
    </description>
    <name>hbase.http.staticuser.user</name>
    <value>dr.stack</value>
  </property>
</configuration>
