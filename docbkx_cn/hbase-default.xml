<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->

<!--
OVERVIEW

The important configs. are listed near the top.  You should change
at least the setting for hbase.tmp.dir.  Other settings will change
dependent on whether you are running hbase in standalone mode or
distributed.  See the hbase reference guide for requirements and
guidance making configuration.

This file does not contain all possible configurations.  The file would be
much larger if it carried everything. The absent configurations will only be
found through source code reading.  The idea is that such configurations are
exotic and only those who would go to the trouble of reading a particular
section in the code would be knowledgeable or invested enough in ever wanting
to alter such configurations, so we do not list them here.  Listing all
possible configurations would overwhelm and obscure the important.
-->

<configuration>

  <!--Configs you will likely change are listed here at the top of the file.
  -->
  <property >
    <name>hbase.tmp.dir</name>
    <value>${java.io.tmpdir}/hbase-${user.name}</value>
    <description>本地文件系统上的临时目录。将'/tmp'改为其他可以持久保存文件的位置，通常能够解决java.io.tmpdir。'/tmp'目录在机器重启后将会被清空。</description>
  </property>
  <property >
    <name>hbase.rootdir</name>
    <value>${hbase.tmp.dir}/hbase</value>
    <description>该目录被region server共享并且用来保存HBase的持久化数据。这个URL应该完全按照文件系统模式的格式来指定。例如，假定使用HDFS目录'/hbase'，并且HDFS的namenode运行在namenode.example.org的9000端口上，那么，该值应该是：
    hdfs://namenode.example.org:9000/hbase。默认情况下，我们也应该将${hbase.tmp.dir}以这种格式进行设置，通常${hbase.tmp.dir}目录的值为/tmp。因此需要该变该值以可以防止数据在机器重启后丢失。</description>
  </property>
  <property >
    <name>hbase.cluster.distributed</name>
    <value>false</value>
    <description>该值指定了集群运行的模式。如果该值为false，表示运行在单机模式，如果该值为true，表示运行在分布式模式。当该值为false时，将会在同一个JVM中启动HBase和Zookeeper的守护进程。</description>
  </property>
  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>localhost</value>
    <description>Zookeeper服务器使用逗号分隔（这个配置项应该被命名为hbase.zookeeper.ensemble）。例如，"host1.mydomain.com,host2.mydomain.com,host3.mydomain.com"。默认该值被设置为localhost以便单机模式和伪分布式模式进行操作。对于完全分布式模式，它应该被设定为Zookeeper服务器的列表。如果hbase-env.sh中设定了HBASE_MANAGES_ZK，那么当集群启动/关闭的时候，也会按照该值启动/关闭Zookeeper。在客户端，我们将确定这个列表的值并且将该值与hbase.zookeeper.clientPort的值组合到一起，然后作为一个字符串参数传递给zookeeper的构造器。</description>
  </property>
  <!--The above are the important configurations for getting hbase up
    and running -->

  <property>
    <name>hbase.local.dir</name>
    <value>${hbase.tmp.dir}/local/</value>
    <description>本地文件系统的目录，用作本地存储。</description>
  </property>

  <!--Master configurations-->
  <property>
    <name>hbase.master.info.port</name>
    <value>16010</value>
    <description>HBase Master的web界面。如果你不想使用web界面，那么将该值设置为-1。</description>
  </property>
  <property>
    <name>hbase.master.info.bindAddress</name>
    <value>0.0.0.0</value>
    <description>HBase Master的web界面的地址。
    </description>
  </property>
  <property>
    <name>hbase.master.logcleaner.plugins</name>
    <value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner</value>
    <description>WAL/HLog清理程序。类名之间以逗号分割，类会被LogsCleaner服务顺序调用，这样就可以删除最早的HLog文件。用户可以实现自己的日志清理程序，只需要在HBase的classpath中加入完整的类名，将上述的日志清理类将hbase-site.xml文件中的默认设置覆盖即可。</description>
  </property>
  <property>
    <name>hbase.master.logcleaner.ttl</name>
    <value>600000</value>
    <description>HLog文件在.oldlogdir目录中最长的生命周期，一旦超过这个值，HLog就会被Master的线程清理掉。</description>
  </property>
  <property>
    <name>hbase.master.hfilecleaner.plugins</name>
    <value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner</value>
    <description>HFile清理程序。类名之间以逗号分割，类会被HFileCleaner服务顺序调用，这样可以删除最早的HFile文件。用户可以实现自己的HFile清理程序，只需要在HBase的classpath中加入完整的类名，将上述的HFile清理类将hbase-site.xml文件中的默认设置覆盖即可。</description>
  </property>
  <property>
    <name>hbase.master.catalog.timeout</name>
    <value>600000(1分钟)</value>
    <description>master监控.META目录的超时时间。</description>
  </property>
  <property>
    <name>hbase.master.infoserver.redirect</name>
    <value>true</value>
    <description>无论Master是否监听了Master的网页UI端口(hbase.master.info.port)，都将请求重定向到Master和RegionServer共享的网页UI服务器。</description>
  </property>

  <!--RegionServer configurations-->
  <property>
    <name>hbase.regionserver.port</name>
    <value>16020</value>
    <description>HBase RegionServer绑定的端口。</description>
  </property>
  <property>
    <name>hbase.regionserver.info.port</name>
    <value>16030</value>
    <description>这是HBase RegionServer的网页UI端口。如果你不想运行RegionServer的网页UI，就将该值设置为-1。
    </description>
  </property>
  <property>
    <name>hbase.regionserver.info.bindAddress</name>
    <value>0.0.0.0</value>
    <description>HBase RegionServer网页UI的绑定地址</description>
  </property>
  <property>
    <name>hbase.regionserver.info.port.auto</name>
    <value>false</value>
    <description>Master或RegionServer是否应该寻找绑定的UI端口。如果hbase.regionserver.info.port已经在使用，就启用自动端口寻找功能。该值在测试时很有用，默认被关闭。</description>
  </property>
  <property>
    <name>hbase.regionserver.handler.count</name>
    <value>30</value>
    <description>在RegionServer上统计RPC监听器实例的数量。同样的属性被master用来统计master处理器的数量。
    </description>
  </property>
  <property>
    <name>hbase.ipc.server.callqueue.handler.factor</name>
    <value>0.1</value>
    <description>Factor to determine the number of call queues.
      A value of 0 means a single queue shared between all the handlers.
      A value of 1 means that each handler has its own queue.</description>
  </property>
<property>
    <name>hbase.ipc.server.callqueue.read.ratio</name>
    <value>0</value>
    <description>Split the call queues into read and write queues.
      The specified interval (which should be between 0.0 and 1.0)
      will be multiplied by the number of call queues.
      A value of 0 indicate to not split the call queues, meaning that both read and write
      requests will be pushed to the same set of queues.
      A value lower than 0.5 means that there will be less read queues than write queues.
      A value of 0.5 means there will be the same number of read and write queues.
      A value greater than 0.5 means that there will be more read queues than write queues.
      A value of 1.0 means that all the queues except one are used to dispatch read requests.

      Example: Given the total number of call queues being 10
      a read.ratio of 0 means that: the 10 queues will contain both read/write requests.
      a read.ratio of 0.3 means that: 3 queues will contain only read requests
      and 7 queues will contain only write requests.
      a read.ratio of 0.5 means that: 5 queues will contain only read requests
      and 5 queues will contain only write requests.
      a read.ratio of 0.8 means that: 8 queues will contain only read requests
      and 2 queues will contain only write requests.
      a read.ratio of 1 means that: 9 queues will contain only read requests
      and 1 queues will contain only write requests.
    </description>
  </property>
  <property>
    <name>hbase.ipc.server.callqueue.scan.ratio</name>
    <value>0</value>
    <description>Given the number of read call queues, calculated from the total number
      of call queues multiplied by the callqueue.read.ratio, the scan.ratio property
      will split the read call queues into small-read and long-read queues.
      A value lower than 0.5 means that there will be less long-read queues than short-read queues.
      A value of 0.5 means that there will be the same number of short-read and long-read queues.
      A value greater than 0.5 means that there will be more long-read queues than short-read queues
      A value of 0 or 1 indicate to use the same set of queues for gets and scans.

      Example: Given the total number of read call queues being 8
      a scan.ratio of 0 or 1 means that: 8 queues will contain both long and short read requests.
      a scan.ratio of 0.3 means that: 2 queues will contain only long-read requests
      and 6 queues will contain only short-read requests.
      a scan.ratio of 0.5 means that: 4 queues will contain only long-read requests
      and 4 queues will contain only short-read requests.
      a scan.ratio of 0.8 means that: 6 queues will contain only long-read requests
      and 2 queues will contain only short-read requests.
    </description>
  </property>
  <property>
    <name>hbase.regionserver.msginterval</name>
    <value>3000</value>
    <description>Interval between messages from the RegionServer to Master
    in milliseconds.</description>
  </property>
  <property>
    <name>hbase.regionserver.regionSplitLimit</name>
    <value>2147483647</value>
    <description>Limit for the number of regions after which no more region
    splitting should take place. This is not a hard limit for the number of
    regions but acts as a guideline for the regionserver to stop splitting after
    a certain limit. Default is MAX_INT; i.e. do not block splitting.</description>
  </property>
  <property>
    <name>hbase.regionserver.logroll.period</name>
    <value>3600000</value>
    <description>Period at which we will roll the commit log regardless
    of how many edits it has.</description>
  </property>
  <property>
    <name>hbase.regionserver.logroll.errors.tolerated</name>
    <value>2</value>
    <description>The number of consecutive WAL close errors we will allow
    before triggering a server abort.  A setting of 0 will cause the
    region server to abort if closing the current WAL writer fails during
    log rolling.  Even a small value (2 or 3) will allow a region server
    to ride over transient HDFS errors.</description>
  </property>
  <property>
    <name>hbase.regionserver.hlog.reader.impl</name>
    <value>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader</value>
    <description>The HLog file reader implementation.</description>
  </property>
  <property>
    <name>hbase.regionserver.hlog.writer.impl</name>
    <value>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter</value>
    <description>The HLog file writer implementation.</description>
  </property>
  <property>
    <name>hbase.master.distributed.log.replay</name>
    <value>true</value>
    <description>Enable 'distributed log replay' as default engine splitting
    WAL files on server crash.  This default is new in hbase 1.0.  To fall
    back to the old mode 'distributed log splitter', set the value to
    'false'.  'Disributed log replay' improves MTTR because it does not
    write intermediate files.  'DLR' required that 'hfile.format.version'
    be set to version 3 or higher. 
    </description>
  </property>
  <property>
    <name>hbase.regionserver.global.memstore.size</name>
    <value>0.4</value>
    <description>Maximum size of all memstores in a region server before new
      updates are blocked and flushes are forced. Defaults to 40% of heap.
      Updates are blocked and flushes are forced until size of all memstores
      in a region server hits hbase.regionserver.global.memstore.size.lower.limit.</description>
  </property>
  <property>
    <name>hbase.regionserver.global.memstore.size.lower.limit</name>
    <value>0.95</value>
    <description>Maximum size of all memstores in a region server before flushes are forced.
      Defaults to 95% of hbase.regionserver.global.memstore.size.
      A 100% value for this value causes the minimum possible flushing to occur when updates are 
      blocked due to memstore limiting.</description>
  </property>
  <property>
    <name>hbase.regionserver.optionalcacheflushinterval</name>
    <value>3600000</value>
    <description>
    Maximum amount of time an edit lives in memory before being automatically flushed.
    Default 1 hour. Set it to 0 to disable automatic flushing.</description>
  </property>
  <property>
    <name>hbase.regionserver.catalog.timeout</name>
    <value>600000</value>
    <description>Timeout value for the Catalog Janitor from the regionserver to META.</description>
  </property>
  <property>
    <name>hbase.regionserver.dns.interface</name>
    <value>default</value>
    <description>The name of the Network Interface from which a region server
      should report its IP address.</description>
  </property>
  <property>
    <name>hbase.regionserver.dns.nameserver</name>
    <value>default</value>
    <description>The host name or IP address of the name server (DNS)
      which a region server should use to determine the host name used by the
      master for communication and display purposes.</description>
  </property>
  <property>
    <name>hbase.regionserver.region.split.policy</name>
    <value>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy</value>
    <description>
      A split policy determines when a region should be split. The various other split policies that
      are available currently are ConstantSizeRegionSplitPolicy, DisabledRegionSplitPolicy, 
      DelimitedKeyPrefixRegionSplitPolicy, KeyPrefixRegionSplitPolicy etc.  
    </description>
  </property>

  <!--ZooKeeper configuration-->
  <property>
    <name>zookeeper.session.timeout</name>
    <value>90000(90秒)</value>
    <description>ZooKeeper会话超时时间。单位是毫秒。它被用于两种不同的情况。其一，这个值被ZooKeeper客户端在和HBase建立链接时使用。它也被HBase用来启动Zookeeper服务器作为建立绘画的最大超时时间-'maxSessionTimeout'。查看
      http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions。
      例如，如果HBase region server连接被HBase管理的Zookeeper，会话超时时间将会由这个配置项指定。但是连接Zookeeper的region服务器使用和Zookeeper的该配置不同的值来进行链接时，将会使用Zookeeper的该配置的值。因此，尽管可能HBase指定的超时时间是90秒，但是如果Zookeeper指定的时间比90秒更少，那么Zookeeper的配置将会被优先使用。当前Zookeeper的默认值是40秒，比HBase默认的该值要低。
    </description>
  </property>
  <property>
    <name>zookeeper.znode.parent</name>
    <value>/hbase</value>
    <description>HBase在ZooKeeper中的根ZNode。 所有HBase的ZooKeeper文件的路径都使用了在这个node下的相对路径。
      默认情况下，所有HBase的ZooKeeper文件路径都配置成了相对路径。因此，除非被改变，否则它们都会到这个目录下进行操作。
      </description>
  </property>
  <property>
    <name>zookeeper.znode.rootserver</name>
    <value>root-region-server</value>
    <description>保存根region位置的ZNode路径，这个值由master来更新，由客户端和region服务器来读取。如果将其设置为一个相对地址，父目录就是 ${zookeeper.znode.parent}。默认情况下，根region位置的存储路径是/hbase/root-region-server。</description>
  </property>
  <property>
    <name>zookeeper.znode.acl.parent</name>
    <value>acl</value>
    <description>根ZNode的访问控制列表。</description>
  </property>
  <property>
    <name>hbase.zookeeper.dns.interface</name>
    <value>default</value>
    <description>汇报自己IP地址的Zookeeper服务器的网络接口名。</description>
  </property>
  <property>
    <name>hbase.zookeeper.dns.nameserver</name>
    <value>default</value>
    <description>ZooKeeper服务器用来确定正在通信的master的主机名的域名服务器(DNS)的主机名或IP地址。</description>
  </property>
  <!--
  The following three properties are used together to create the list of
  host:peer_port:leader_port quorum servers for ZooKeeper.
  -->
  <property>
    <name>hbase.zookeeper.peerport</name>
    <value>2888</value>
    <description>ZooKeeper服务器之间彼此通信使用的接口。查看http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper
    可以找到更多信息。</description>
  </property>
  <property>
    <name>hbase.zookeeper.leaderport</name>
    <value>3888</value>
    <description>在ZooKeeper领导选举中使用的端口地址。
    查看http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper
    可以找到更多信息。</description>
  </property>
  <!-- End of properties used to generate ZooKeeper host:port quorum list. -->
  <property>
    <name>hbase.zookeeper.useMulti</name>
    <value>false</value>
    <description>Instructs HBase to make use of ZooKeeper's multi-update functionality.
    This allows certain ZooKeeper operations to complete more quickly and prevents some issues
    with rare Replication failure scenarios (see the release note of HBASE-2611 for an example).
    IMPORTANT: only set this to true if all ZooKeeper servers in the cluster are on version 3.4+
    and will not be downgraded.  ZooKeeper versions before 3.4 do not support multi-update and
    will not fail gracefully if multi-update is invoked (see ZOOKEEPER-1495).</description>
  </property>
  <property>
    <name>hbase.config.read.zookeeper.config</name>
    <value>false</value>
    <description>
        Set to true to allow HBaseConfiguration to read the
        zoo.cfg file for ZooKeeper properties. Switching this to true
        is not recommended, since the functionality of reading ZK
        properties from a zoo.cfg file has been deprecated.</description>
  </property>
  <!--
  Beginning of properties that are directly mapped from ZooKeeper's zoo.cfg.
  All properties with an "hbase.zookeeper.property." prefix are converted for
  ZooKeeper's configuration. Hence, if you want to add an option from zoo.cfg,
  e.g.  "initLimit=10" you would append the following to your configuration:
    <property>
      <name>hbase.zookeeper.property.initLimit</name>
      <value>10</value>
    </property>
  -->
  <property>
    <name>hbase.zookeeper.property.initLimit</name>
    <value>10</value>
    <description>Property from ZooKeeper's config zoo.cfg.
    The number of ticks that the initial synchronization phase can take.</description>
  </property>
  <property>
    <name>hbase.zookeeper.property.syncLimit</name>
    <value>5</value>
    <description>Property from ZooKeeper's config zoo.cfg.
    The number of ticks that can pass between sending a request and getting an
    acknowledgment.</description>
  </property>
  <property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>${hbase.tmp.dir}/zookeeper</value>
    <description>Property from ZooKeeper's config zoo.cfg.
    The directory where the snapshot is stored.</description>
  </property>
  <property>
    <name>hbase.zookeeper.property.clientPort</name>
    <value>2181</value>
    <description>Property from ZooKeeper's config zoo.cfg.
    The port at which the clients will connect.</description>
  </property>
  <property>
    <name>hbase.zookeeper.property.maxClientCnxns</name>
    <value>300</value>
    <description>Property from ZooKeeper's config zoo.cfg.
    Limit on number of concurrent connections (at the socket level) that a
    single client, identified by IP address, may make to a single member of
    the ZooKeeper ensemble. Set high to avoid zk connection issues running
    standalone and pseudo-distributed.</description>
  </property>
  <!-- End of properties that are directly mapped from ZooKeeper's zoo.cfg -->

  <!--Client configurations-->
  <property>
    <name>hbase.client.write.buffer</name>
    <value>2097152</value>
    <description>Default size of the HTable client write buffer in bytes.
    A bigger buffer takes more memory -- on both the client and server
    side since server instantiates the passed write buffer to process
    it -- but a larger buffer size reduces the number of RPCs made.
    For an estimate of server-side memory-used, evaluate
    hbase.client.write.buffer * hbase.regionserver.handler.count</description>
  </property>
  <property>
    <name>hbase.client.pause</name>
    <value>100</value>
    <description>General client pause value.  Used mostly as value to wait
    before running a retry of a failed get, region lookup, etc.
    See hbase.client.retries.number for description of how we backoff from
    this initial pause amount and how this pause works w/ retries.</description>
  </property>
  <property>
    <name>hbase.client.retries.number</name>
    <value>35</value>
    <description>Maximum retries.  Used as maximum for all retryable
    operations such as the getting of a cell's value, starting a row update,
    etc.  Retry interval is a rough function based on hbase.client.pause.  At
    first we retry at this interval but then with backoff, we pretty quickly reach
    retrying every ten seconds.  See HConstants#RETRY_BACKOFF for how the backup
    ramps up.  Change this setting and hbase.client.pause to suit your workload.</description>
  </property>
  <property>
    <name>hbase.client.max.total.tasks</name>
    <value>100</value>
    <description>The maximum number of concurrent tasks a single HTable instance will
    send to the cluster.</description>
  </property>
  <property>
    <name>hbase.client.max.perserver.tasks</name>
    <value>5</value>
    <description>The maximum number of concurrent tasks a single HTable instance will
    send to a single region server.</description>
  </property>
  <property>
    <name>hbase.client.max.perregion.tasks</name>
    <value>1</value>
    <description>The maximum number of concurrent connections the client will
    maintain to a single Region. That is, if there is already
    hbase.client.max.perregion.tasks writes in progress for this region, new puts
    won't be sent to this region until some writes finishes.</description>
  </property>
  <property>
    <name>hbase.client.scanner.caching</name>
    <value>100</value>
    <description>Number of rows that will be fetched when calling next
    on a scanner if it is not served from (local, client) memory. Higher
    caching values will enable faster scanners but will eat up more memory
    and some calls of next may take longer and longer times when the cache is empty.
    Do not set this value such that the time between invocations is greater
    than the scanner timeout; i.e. hbase.client.scanner.timeout.period</description>
  </property>
  <property>
    <name>hbase.client.keyvalue.maxsize</name>
    <value>10485760</value>
    <description>Specifies the combined maximum allowed size of a KeyValue
    instance. This is to set an upper boundary for a single entry saved in a
    storage file. Since they cannot be split it helps avoiding that a region
    cannot be split any further because the data is too large. It seems wise
    to set this to a fraction of the maximum region size. Setting it to zero
    or less disables the check.</description>
  </property>
  <property>
    <name>hbase.client.scanner.timeout.period</name>
    <value>60000</value>
    <description>Client scanner lease period in milliseconds.</description>
  </property>
  <property>
    <name>hbase.client.localityCheck.threadPoolSize</name>
    <value>2</value>
  </property>

  <!--Miscellaneous configuration-->
  <property>
    <name>hbase.bulkload.retries.number</name>
    <value>0</value>
    <description>Maximum retries.  This is maximum number of iterations
    to atomic bulk loads are attempted in the face of splitting operations
    0 means never give up.</description>
  </property>
  <property>
    <name>hbase.balancer.period
    </name>
    <value>300000(5分钟)</value>
    <description>在Master节点中运行region负载均衡器的周期。</description>
  </property>
  <property>
    <name>hbase.balancer.backupMasterWeight</name>
    <value>1</value>
    <description>Used to control how many regions the region balancer can assign to
    backup Masters, compared to normal region servers. The default value 1 means a
    backup Master can host as many regions as a normal region server. The bigger the
    weight, the less the regions a backup Master will host. If the weight is less than 1,
    the balancer will not assign any region to any backup Master</description>
  </property>
  <property>
    <name>hbase.regions.slop</name>
    <value>0.2</value>
    <description>Rebalance if any regionserver has average + (average * slop) regions.</description>
  </property>
  <property>
    <name>hbase.server.thread.wakefrequency</name>
    <value>10000</value>
    <description>Time to sleep in between searches for work (in milliseconds).
    Used as sleep interval by service threads such as log roller.</description>
  </property>
  <property>
    <name>hbase.server.versionfile.writeattempts</name>
    <value>3</value>
    <description>
    How many time to retry attempting to write a version file
    before just aborting. Each attempt is seperated by the
    hbase.server.thread.wakefrequency milliseconds.</description>
  </property>
  <property>
    <name>hbase.hregion.memstore.flush.size</name>
    <value>134217728(128*1024*1024字节)</value>
    <description>
    如果Memstore的大小超过这个值，Memstore的数据就会刷写到磁盘中。这个值由一个线程每隔hbase.server.thread.wakefrequency检查一次。</description>
  </property>
  <property>
    <name>hbase.hregion.preclose.flush.size</name>
    <value>5242880</value>
    <description>
      当我们要关闭一个region，而该region的memstore的大小大于这个值，那么就会先运行“预刷写”操作，清理这个需要关闭的memstore，然后再将这个region下线。在关闭region时，关闭标签会触发一次清空内存的刷写。在region处于下线过程中时，我们就无法再对其进行任何写操作了。如果一个memstore的内容很大，刷写磁盘的操作就会消耗很多时间。预刷写操作意味着在region被打上关闭标签之前，会先把memstore清空。这样在最终执行关闭操作的时候，带关闭操作的刷写速度会很快。</description>
  </property>
  <property>
    <name>hbase.hregion.memstore.block.multiplier</name>
    <value>4</value>
    <description>
    如果memstore达到了hbase.hregion.memstore.block.multiplier
    乘以hbase.hregion.memstore.flush.size的大小，就会阻塞更新操作。这是为了预防在更新高峰期或导致的失控。如果不设上界，刷写的时候会花费很长的时间来合并或者拆分，最坏的情况会引发OOME异常。</description>
  </property>
  <property>
    <name>hbase.hregion.memstore.mslab.enabled</name>
    <value>true</value>
    <description>
      启动本地MemStore分配缓冲区(MemStore-Local Allocation Buffer)，这个特性是为了防止在大量写负载的时候堆的碎片太多。这将降低大堆中垃圾回收的频率。</description>
  </property>
  <property>
    <name>hbase.hregion.max.filesize</name>
    <value>10737418240 (10*1024*1024*1024字节)</value>
    <description>
    HFile的最大大小。如果一个region的HFile总的大小超过了这个上线，那么它会被拆分为两个region。</description>
  </property>
  <property>
    <name>hbase.hregion.majorcompaction</name>
    <value>604800000(7天)</value>
    <description>两次major合并的间隔时间，单位是毫秒。默认值是7天。将其设置为0可以禁用major合并。当用户请求major合并或者满足major合并要求时将会进行。该值乘以hbase.hregion.majorcompaction.jitter的值以便在一个给定的时间窗口期间的一个随机时间来开启major合并操作。major合并可能会导致集群无法访问，你可以在你的配置中将它设置为在低峰时段运行，或者通过将它设置为0而禁用它，或者通过另外一种额外的机制来定时运行major合并操作。</description>
  </property>
  <property>
    <name>hbase.hregion.majorcompaction.jitter</name>
    <value>0.50</value>
    <description>A multiplier applied to hbase.hregion.majorcompaction to cause compaction to occur
      a given amount of time either side of hbase.hregion.majorcompaction. The smaller the number,
      the closer the compactions will happen to the hbase.hregion.majorcompaction
      interval.</description>
  </property>
  <property>
    <name>hbase.hstore.compactionThreshold</name>
    <value>3</value>
    <description> If more than this number of StoreFiles exist in any one Store 
      (one StoreFile is written per flush of MemStore), a compaction is run to rewrite all 
      StoreFiles into a single StoreFile. Larger values delay compaction, but when compaction does
      occur, it takes longer to complete.</description>
  </property>
  <property>
    <name>hbase.hstore.flusher.count</name>
    <value>2</value>
    <description> The number of flush threads. With fewer threads, the MemStore flushes will be
      queued. With more threads, the flushes will be executed in parallel, increasing the load on
      HDFS, and potentially causing more compactions. </description>
  </property>
  <property>
    <name>hbase.hstore.blockingStoreFiles</name>
    <value>10</value>
    <description> 如果一个Store中StoreFile文件的数目（每次MemStore刷写到磁盘都会产生一个StoreFile文件）大于这个阈值，那么对这个region的更新操作就会被阻塞，直到合并操作完成或者一直阻塞到超过hbase.hstore.blockingWaitTime。</description>
  </property>
  <property>
    <name>hbase.hstore.blockingWaitTime</name>
    <value>90000</value>
    <description> 一个region的StoreFile数目达到了hbase.hstore.blockingStoreFiles设置的值后，它会阻塞对其他客户端的更新请求。超过当前设定的时间之后，即使合并没有完成，也会停止对更新操作的阻塞。</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.min</name>
    <value>3</value>
    <description>可以进行合并的StoreFile在一次合时并必须满足的最小的StoreFile数目。设置hbase.hstore.compaction.min的值是为了防止太多的小的StoreFile被合并。将该值设置为2将会导致一次minor合并每次只能合并2个StoreFile，并且这样可能不太恰当。如果你将该值设定的过大，其他的值也需要被适当的调整。大多数情况下，默认值是适当的。在之前的HBase版本中，hbase.hstore.compaction.min被称为hbase.hstore.compactionThreshold。</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.max</name>
    <value>10</value>
    <description>每次minor合并所要处理的最大的StoreFile数目，无论需要合并的数目是多少。hbase.hstore.compaction.max的值控制着单次合并完成所要花费的时间。将这个值设定的更大意味着一次合并将包括更多的StoreFile文件。大多数情况下，默认值是适当的。</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.min.size</name>
    <value>134217728</value>
    <description>A StoreFile smaller than this size will always be eligible for minor compaction. 
      HFiles this size or larger are evaluated by hbase.hstore.compaction.ratio to determine if 
      they are eligible. Because this limit represents the "automatic include"limit for all 
      StoreFiles smaller than this value, this value may need to be reduced in write-heavy 
      environments where many StoreFiles in the 1-2 MB range are being flushed, because every 
      StoreFile will be targeted for compaction and the resulting StoreFiles may still be under the
      minimum size and require further compaction. If this parameter is lowered, the ratio check is
      triggered more quickly. This addressed some issues seen in earlier versions of HBase but 
      changing this parameter is no longer necessary in most situations. Default: 128 MB expressed 
      in bytes.</description>
  </property>
    <property>
    <name>hbase.hstore.compaction.max.size</name>
    <value>9223372036854775807</value>
    <description>A StoreFile larger than this size will be excluded from compaction. The effect of 
      raising hbase.hstore.compaction.max.size is fewer, larger StoreFiles that do not get 
      compacted often. If you feel that compaction is happening too often without much benefit, you
      can try raising this value. Default: the value of LONG.MAX_VALUE, expressed in bytes.</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.ratio</name>
    <value>1.2F</value>
    <description>For minor compaction, this ratio is used to determine whether a given StoreFile 
      which is larger than hbase.hstore.compaction.min.size is eligible for compaction. Its
      effect is to limit compaction of large StoreFiles. The value of hbase.hstore.compaction.ratio
      is expressed as a floating-point decimal. A large ratio, such as 10, will produce a single 
      giant StoreFile. Conversely, a low value, such as .25, will produce behavior similar to the 
      BigTable compaction algorithm, producing four StoreFiles. A moderate value of between 1.0 and
      1.4 is recommended. When tuning this value, you are balancing write costs with read costs. 
      Raising the value (to something like 1.4) will have more write costs, because you will 
      compact larger StoreFiles. However, during reads, HBase will need to seek through fewer 
      StoreFiles to accomplish the read. Consider this approach if you cannot take advantage of 
      Bloom filters. Otherwise, you can lower this value to something like 1.0 to reduce the 
      background cost of writes, and use Bloom filters to control the number of StoreFiles touched 
      during reads. For most cases, the default value is appropriate.</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.ratio.offpeak</name>
    <value>5.0F</value>
    <description>Allows you to set a different (by default, more aggressive) ratio for determining
      whether larger StoreFiles are included in compactions during off-peak hours. Works in the 
      same way as hbase.hstore.compaction.ratio. Only applies if hbase.offpeak.start.hour and 
      hbase.offpeak.end.hour are also enabled.</description>
  </property>
  <property>
    <name>hbase.hstore.time.to.purge.deletes</name>
    <value>0</value>
    <description>The amount of time to delay purging of delete markers with future timestamps. If 
      unset, or set to 0, all delete markers, including those with future timestamps, are purged 
      during the next major compaction. Otherwise, a delete marker is kept until the major compaction 
      which occurs after the marker's timestamp plus the value of this setting, in milliseconds.
    </description>
  </property>
  <property>
    <name>hbase.offpeak.start.hour</name>
    <value>-1</value>
    <description>The start of off-peak hours, expressed as an integer between 0 and 23, inclusive.
      Set to -1 to disable off-peak.</description>
  </property>
  <property>
    <name>hbase.offpeak.end.hour</name>
    <value>-1</value>
    <description>The end of off-peak hours, expressed as an integer between 0 and 23, inclusive. Set
      to -1 to disable off-peak.</description>
  </property>
  <property>
    <name>hbase.regionserver.thread.compaction.throttle</name>
    <value>2560</value>
    <description>There are two different thread pools for compactions, one for large compactions and
      the other for small compactions. This helps to keep compaction of lean tables (such as
        <systemitem>hbase:meta</systemitem>) fast. If a compaction is larger than this threshold, it
      goes into the large compaction pool. In most cases, the default value is appropriate. Default:
      2 x hbase.hstore.compaction.max x hbase.hregion.memstore.flush.size (which defaults to 128).
      The value field assumes that the value of hbase.hregion.memstore.flush.size is unchanged from
      the default.</description>
  </property>
  <property>
    <name>hbase.hstore.compaction.kv.max</name>
    <value>10</value>
    <description>The maximum number of KeyValues to read and then write in a batch when flushing or
      compacting. Set this lower if you have big KeyValues and problems with Out Of Memory
      Exceptions Set this higher if you have wide, small rows. </description>
  </property>
  <property>
    <name>hbase.storescanner.parallel.seek.enable</name>
    <value>false</value>
    <description>
      Enables StoreFileScanner parallel-seeking in StoreScanner,
      a feature which can reduce response latency under special conditions.</description>
  </property>
  <property>
    <name>hbase.storescanner.parallel.seek.threads</name>
    <value>10</value>
    <description>
      The default thread pool size if parallel-seeking feature enabled.</description>
  </property>
  <property>
    <name>hfile.block.cache.size</name>
    <value>0.4</value>
    <description>Percentage of maximum heap (-Xmx setting) to allocate to block cache
        used by a StoreFile. Default of 0.4 means allocate 40%.
        Set to 0 to disable but it's not recommended; you need at least
        enough cache to hold the storefile indices.</description>
  </property>
  <property>
      <name>hfile.block.index.cacheonwrite</name>
      <value>false</value>
      <description>This allows to put non-root multi-level index blocks into the block
          cache at the time the index is being written.</description>
  </property>
  <property>
      <name>hfile.index.block.max.size</name>
      <value>131072</value>
      <description>When the size of a leaf-level, intermediate-level, or root-level
          index block in a multi-level block index grows to this size, the
          block is written out and a new block is started.</description>
  </property>
  <property>
      <name>hfile.format.version</name>
      <value>3</value>
      <description>The HFile format version to use for new files.
      Version 3 adds support for tags in hfiles (See http://hbase.apache.org/book.html#hbase.tags).
      Distributed Log Replay requires that tags are enabled.
      </description>
  </property>
  <property>
      <name>hfile.block.bloom.cacheonwrite</name>
      <value>false</value>
      <description>Enables cache-on-write for inline blocks of a compound Bloom filter.</description>
  </property>
  <property>
      <name>io.storefile.bloom.block.size</name>
      <value>131072</value>
      <description>The size in bytes of a single block ("chunk") of a compound Bloom
          filter. This size is approximate, because Bloom blocks can only be
          inserted at data block boundaries, and the number of keys per data
          block varies.</description>
  </property>
  <property>
      <name>hbase.rs.cacheblocksonwrite</name>
      <value>false</value>
      <description>Whether an HFile block should be added to the block cache when the
          block is finished.</description>
  </property>
  <property>
    <name>hbase.rpc.server.engine</name>
    <value>org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine</value>
    <description>Implementation of org.apache.hadoop.hbase.ipc.RpcServerEngine to be
    used for server RPC call marshalling.</description>
  </property>
  <property>
    <name>hbase.rpc.timeout</name>
    <value>60000</value>
    <description>This is for the RPC layer to define how long HBase client applications
        take for a remote call to time out. It uses pings to check connections
        but will eventually throw a TimeoutException.</description>
  </property>
  <property>
    <name>hbase.rpc.shortoperation.timeout</name>
    <value>10000</value>
    <description>This is another version of "hbase.rpc.timeout". For those RPC operation
        within cluster, we rely on this configuration to set a short timeout limitation
        for short operation. For example, short rpc timeout for region server's trying
        to report to active master can benefit quicker master failover process.</description>
  </property>
  <property>
    <name>hbase.ipc.client.tcpnodelay</name>
    <value>true</value>
    <description>Set no delay on rpc socket connections.  See
    http://docs.oracle.com/javase/1.5.0/docs/api/java/net/Socket.html#getTcpNoDelay()</description>
  </property>
  <!-- The following properties configure authentication information for
       HBase processes when using Kerberos security.  There are no default
       values, included here for documentation purposes -->
  <property>
    <name>hbase.master.keytab.file</name>
    <value></value>
    <description>用于登录配置的HMaster服务器实体(HMaster server principal)的kerberos keytab文件的完整路径。</description>
  </property>
  <property>
    <name>hbase.master.kerberos.principal</name>
    <value></value>
    <description>例如， "hbase/_HOST@EXAMPLE.COM"。HMaster进程运行时需要使用kerberos实体(kerberos principal)，实体可以使用这种格式：user/hostname@DOMAIN。
        如果"_HOST"部分使用主机名，它在实际运行的时候将使用主机名来替代。</description>
  </property>
  <property>
    <name>hbase.regionserver.keytab.file</name>
    <value></value>
    <description>用于登录配置的HRegionServer服务器实体(HRegionServer server principal)的kerberos keytab文件的完整路径。</description>
  </property>
  <property>
    <name>hbase.regionserver.kerberos.principal</name>
    <value></value>
    <description>例如， "hbase/_HOST@EXAMPLE.COM"。HRegionServer进程运行时需要使用kerberos实体(kerberos principal)，实体可以使用这种格式：user/hostname@DOMAIN。
        如果"_HOST"部分使用主机名，它在实际运行的时候将使用主机名来替代。这个实体的入口必须在hbase.regionserver.keytab.file文件中指定。</description>
  </property>
  <!-- Additional configuration specific to HBase security -->
  <property>
    <name>hadoop.policy.file</name>
    <value>hbase-policy.xml</value>
    <description>The policy configuration file used by RPC servers to make
      authorization decisions on client requests.  Only used when HBase
      security is enabled.</description>
  </property>
  <property>
    <name>hbase.superuser</name>
    <value></value>
    <description>List of users or groups (comma-separated), who are allowed
    full privileges, regardless of stored ACLs, across the cluster.
    Only used when HBase security is enabled.</description>
  </property>
  <property>
    <name>hbase.auth.key.update.interval</name>
    <value>86400000</value>
    <description>The update interval for master key for authentication tokens
    in servers in milliseconds.  Only used when HBase security is enabled.</description>
  </property>
  <property>
    <name>hbase.auth.token.max.lifetime</name>
    <value>604800000</value>
    <description>The maximum lifetime in milliseconds after which an
    authentication token expires.  Only used when HBase security is enabled.</description>
  </property>
  <property>
    <name>hbase.ipc.client.fallback-to-simple-auth-allowed</name>
    <value>false</value>
    <description>When a client is configured to attempt a secure connection, but attempts to
      connect to an insecure server, that server may instruct the client to
      switch to SASL SIMPLE (unsecure) authentication. This setting controls
      whether or not the client will accept this instruction from the server.
      When false (the default), the client will not allow the fallback to SIMPLE
      authentication, and will abort the connection.</description>
  </property>
  <property>
    <name>hbase.display.keys</name>
    <value>true</value>
    <description>When this is set to true the webUI and such will display all start/end keys
                 as part of the table details, region names, etc. When this is set to false,
                 the keys are hidden.</description>
  </property>
  <property>
    <name>hbase.coprocessor.region.classes</name>
    <value></value>
    <description>协处理器之间使用逗号分隔，这些协处理器默认会被所有的表加载。用户可以实现自己的协处理器，只需将其添加到HBase的classpath中，并在此配置完整类名。用户也可以根据需求设置HTableDescriptor来选择性的加载协处理器。</description>
  </property>
  <property>
    <name>hbase.rest.port</name>
    <value>8080</value>
    <description>The port for the HBase REST server.</description>
  </property>
  <property>
    <name>hbase.rest.readonly</name>
    <value>false</value>
    <description>Defines the mode the REST server will be started in. Possible values are:
    false: All HTTP methods are permitted - GET/PUT/POST/DELETE.
    true: Only the GET method is permitted.</description>
  </property>
  <property>
    <name>hbase.rest.threads.max</name>
    <value>100</value>
    <description>The maximum number of threads of the REST server thread pool.
        Threads in the pool are reused to process REST requests. This
        controls the maximum number of requests processed concurrently.
        It may help to control the memory used by the REST server to
        avoid OOM issues. If the thread pool is full, incoming requests
        will be queued up and wait for some free threads.</description>
  </property>
  <property>
    <name>hbase.rest.threads.min</name>
    <value>2</value>
    <description>The minimum number of threads of the REST server thread pool.
        The thread pool always has at least these number of threads so
        the REST server is ready to serve incoming requests.</description>
  </property>
  <property>
    <name>hbase.rest.support.proxyuser</name>
    <value>false</value>
    <description>Enables running the REST server to support proxy-user mode.</description>
  </property>
  <property skipInDoc="true">
    <name>hbase.defaults.for.version</name>
    <value>@@@VERSION@@@</value>
    <description>默认值是是被编译的${project.version}的版本号。这个值用来确定用户在classpath中没有一个旧版本的hbase-default.xml。</description>
  </property>
  <property>
    <name>hbase.defaults.for.version.skip</name>
    <value>false</value>
    <description>将当前参数设置为true可以跳过'hbase.defaults.for.version'检查。将该参数设置为true，它会在上下文中发挥作用。这一点不同于它在maven下的使用方法，即在IDE中通过maven使用HBase。用户也可以将该参数设置为true，以避免因为hbase-default.xml中的版本检查通不过而产生的运行时异常："hbase-default.xml file
    seems to be for and old version of HBase (\${hbase.version}), this
    version is X.X.X-SNAPSHOT"。</description>
  </property>
  <property>
    <name>hbase.coprocessor.master.classes</name>
    <value></value>
    <description>HMaster进程默认使用的协处理器是org.apache.hadoop.hbase.coprocessor.MasterObserver，在该配置中，协处理器之间使用逗号分隔，协处理器中实现的方法将按照配置顺序执行。用户可以通过继承MasterObserver来实现自己的协处理器，只需要将其添加到classpath，并添加可用的类名。</description>
  </property>
  <property>
      <name>hbase.coprocessor.abortonerror</name>
      <value>true</value>
      <description>Set to true to cause the hosting server (master or regionserver)
      to abort if a coprocessor fails to load, fails to initialize, or throws an
      unexpected Throwable object. Setting this to false will allow the server to
      continue execution but the system wide state of the coprocessor in question
      will become inconsistent as it will be properly executing in only a subset
      of servers, so this is most useful for debugging only.</description>
  </property>
  <property>
    <name>hbase.online.schema.update.enable</name>
    <value>true</value>
    <description>Set true to enable online schema changes.</description>
  </property>
  <property>
    <name>hbase.table.lock.enable</name>
    <value>true</value>
    <description>Set to true to enable locking the table in zookeeper for schema change operations.
    Table locking from master prevents concurrent schema modifications to corrupt table
    state.</description>
  </property>
  <property>
    <name>hbase.table.max.rowsize</name>
    <value>1073741824</value>
    <description>
      Maximum size of single row in bytes (default is 1 Gb) for Get'ting
      or Scan'ning without in-row scan flag set. If row size exceeds this limit
      RowTooBigException is thrown to client.
    </description>
  </property>
  <property>
    <name>hbase.thrift.minWorkerThreads</name>
    <value>16</value>
    <description>The "core size" of the thread pool. New threads are created on every
    connection until this many threads are created.</description>
  </property>
  <property>
    <name>hbase.thrift.maxWorkerThreads</name>
    <value>1000</value>
    <description>The maximum size of the thread pool. When the pending request queue
    overflows, new threads are created until their number reaches this number.
    After that, the server starts dropping connections.</description>
  </property>
  <property>
    <name>hbase.thrift.maxQueuedRequests</name>
    <value>1000</value>
    <description>The maximum number of pending Thrift connections waiting in the queue. If
     there are no idle threads in the pool, the server queues requests. Only
     when the queue overflows, new threads are added, up to
     hbase.thrift.maxQueuedRequests threads.</description>
  </property>
  <property>
    <name>hbase.thrift.htablepool.size.max</name>
    <value>1000</value>
    <description>The upper bound for the table pool used in the Thrift gateways server.
      Since this is per table name, we assume a single table and so with 1000 default
      worker threads max this is set to a matching number. For other workloads this number
      can be adjusted as needed.
    </description>
  </property>
  <property>
    <name>hbase.regionserver.thrift.framed</name>
    <value>false</value>
    <description>Use Thrift TFramedTransport on the server side.
      This is the recommended transport for thrift servers and requires a similar setting
      on the client side. Changing this to false will select the default transport,
      vulnerable to DoS when malformed requests are issued due to THRIFT-601.
    </description>
  </property>
  <property>
   <name>hbase.regionserver.thrift.framed.max_frame_size_in_mb</name>
    <value>2</value>
    <description>Default frame size when using framed transport</description>
  </property>
  <property>
    <name>hbase.regionserver.thrift.compact</name>
    <value>false</value>
    <description>Use Thrift TCompactProtocol binary serialization protocol.</description>
  </property>
  <property>
    <name>hbase.data.umask.enable</name>
    <value>false</value>
    <description>Enable, if true, that file permissions should be assigned
      to the files written by the regionserver</description>
  </property>
  <property>
    <name>hbase.data.umask</name>
    <value>000</value>
    <description>File permissions that should be used to write data
      files when hbase.data.umask.enable is true</description>
  </property>
  <property>
    <name>hbase.metrics.showTableName</name>
    <value>true</value>
    <description>Whether to include the prefix "tbl.tablename" in per-column family metrics.
	If true, for each metric M, per-cf metrics will be reported for tbl.T.cf.CF.M, if false,
	per-cf metrics will be aggregated by column-family across tables, and reported for cf.CF.M.
	In both cases, the aggregated metric M across tables and cfs will be reported.</description>
  </property>
  <property>
    <name>hbase.metrics.exposeOperationTimes</name>
    <value>true</value>
    <description>Whether to report metrics about time taken performing an
      operation on the region server.  Get, Put, Delete, Increment, and Append can all
      have their times exposed through Hadoop metrics per CF and per region.</description>
  </property>
  <property>
    <name>hbase.snapshot.enabled</name>
    <value>true</value>
    <description>Set to true to allow snapshots to be taken / restored / cloned.</description>
  </property>
  <property>
    <name>hbase.snapshot.restore.take.failsafe.snapshot</name>
    <value>true</value>
    <description>Set to true to take a snapshot before the restore operation.
      The snapshot taken will be used in case of failure, to restore the previous state.
      At the end of the restore operation this snapshot will be deleted</description>
  </property>
  <property>
    <name>hbase.snapshot.restore.failsafe.name</name>
    <value>hbase-failsafe-{snapshot.name}-{restore.timestamp}</value>
    <description>Name of the failsafe snapshot taken by the restore operation.
      You can use the {snapshot.name}, {table.name} and {restore.timestamp} variables
      to create a name based on what you are restoring.</description>
  </property>
  <property>
    <name>hbase.server.compactchecker.interval.multiplier</name>
    <value>1000</value>
    <description>The number that determines how often we scan to see if compaction is necessary.
        Normally, compactions are done after some events (such as memstore flush), but if
        region didn't receive a lot of writes for some time, or due to different compaction
        policies, it may be necessary to check it periodically. The interval between checks is
        hbase.server.compactchecker.interval.multiplier multiplied by
        hbase.server.thread.wakefrequency.</description>
  </property>
  <property>
    <name>hbase.lease.recovery.timeout</name>
    <value>900000</value>
    <description>How long we wait on dfs lease recovery in total before giving up.</description>
  </property>
  <property>
    <name>hbase.lease.recovery.dfs.timeout</name>
    <value>64000</value>
    <description>How long between dfs recover lease invocations. Should be larger than the sum of
        the time it takes for the namenode to issue a block recovery command as part of
        datanode; dfs.heartbeat.interval and the time it takes for the primary
        datanode, performing block recovery to timeout on a dead datanode; usually
        dfs.client.socket-timeout. See the end of HBASE-8389 for more.</description>
  </property>
  <property>
    <name>hbase.column.max.version</name>
    <value>1</value>
    <description>New column family descriptors will use this value as the default number of versions
      to keep.</description>
  </property>
  <property>
    <name>hbase.dfs.client.read.shortcircuit.buffer.size</name>
    <value>131072</value>
    <description>If the DFSClient configuration
    dfs.client.read.shortcircuit.buffer.size is unset, we will
    use what is configured here as the short circuit read default
    direct byte buffer size. DFSClient native default is 1MB; HBase
    keeps its HDFS files open so number of file blocks * 1MB soon
    starts to add up and threaten OOME because of a shortage of
    direct memory.  So, we set it down from the default.  Make
    it > the default hbase block size set in the HColumnDescriptor
    which is usually 64k.
    </description>
  </property>
  <property>
    <name>hbase.regionserver.checksum.verify</name>
    <value>true</value>
    <description>
        If set to true (the default), HBase verifies the checksums for hfile
        blocks. HBase writes checksums inline with the data when it writes out
        hfiles. HDFS (as of this writing) writes checksums to a separate file
        than the data file necessitating extra seeks.  Setting this flag saves
        some on i/o.  Checksum verification by HDFS will be internally disabled
        on hfile streams when this flag is set.  If the hbase-checksum verification
        fails, we will switch back to using HDFS checksums (so do not disable HDFS
        checksums!  And besides this feature applies to hfiles only, not to WALs).
        If this parameter is set to false, then hbase will not verify any checksums,
        instead it will depend on checksum verification being done in the HDFS client.  
    </description>
  </property>
  <property>
    <name>hbase.hstore.bytes.per.checksum</name>
    <value>16384</value>
    <description>
        Number of bytes in a newly created checksum chunk for HBase-level
        checksums in hfile blocks.
    </description>
  </property>
  <property>
    <name>hbase.hstore.checksum.algorithm</name>
    <value>CRC32</value>
    <description>
      Name of an algorithm that is used to compute checksums. Possible values
      are NULL, CRC32, CRC32C.
    </description>
  </property>

  <property>
    <name>hbase.status.published</name>
    <value>false</value>
    <description>
      This setting activates the publication by the master of the status of the region server.
      When a region server dies and its recovery starts, the master will push this information
      to the client application, to let them cut the connection immediately instead of waiting
      for a timeout.
    </description>
  </property>
  <property>
    <name>hbase.status.publisher.class</name>
    <value>org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher</value>
    <description>
      Implementation of the status publication with a multicast message.
    </description>
  </property>
  <property>
    <name>hbase.status.listener.class</name>
    <value>org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener</value>
    <description>
      Implementation of the status listener with a multicast message.
    </description>
  </property>
  <property>
    <name>hbase.status.multicast.address.ip</name>
    <value>226.1.1.3</value>
    <description>
      Multicast address to use for the status publication by multicast.
    </description>
  </property>
  <property>
    <name>hbase.status.multicast.address.port</name>
    <value>16100</value>
    <description>
      Multicast port to use for the status publication by multicast.
    </description>
  </property>

  <property>
    <name>hbase.dynamic.jars.dir</name>
    <value>${hbase.rootdir}/lib</value>
    <description>
      The directory from which the custom filter/co-processor jars can be loaded
      dynamically by the region server without the need to restart. However,
      an already loaded filter/co-processor class would not be un-loaded. See
      HBASE-1936 for more details.
    </description>
  </property>
  <property>
    <name>hbase.security.authentication</name>
    <value>simple</value>
    <description>
      Controls whether or not secure authentication is enabled for HBase.
      Possible values are 'simple' (no authentication), and 'kerberos'.
    </description>
  </property>
  <property>
    <name>hbase.rest.filter.classes</name>
    <value>org.apache.hadoop.hbase.rest.filter.GzipFilter</value>
    <description>
      Servlet filters for REST service.
    </description>
  </property>
  <property>
    <name>hbase.master.loadbalancer.class</name>
    <value>org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer</value>
    <description>
      Class used to execute the regions balancing when the period occurs.
      See the class comment for more on how it works
      http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.html
      It replaces the DefaultLoadBalancer as the default (since renamed
      as the SimpleLoadBalancer).
    </description>
  </property>
  <property>
    <name>hbase.security.exec.permission.checks</name>
    <value>false</value>
    <description>
      If this setting is enabled and ACL based access control is active (the
      AccessController coprocessor is installed either as a system coprocessor
      or on a table as a table coprocessor) then you must grant all relevant
      users EXEC privilege if they require the ability to execute coprocessor
      endpoint calls. EXEC privilege, like any other permission, can be
      granted globally to a user, or to a user on a per table or per namespace
      basis. For more information on coprocessor endpoints, see the coprocessor
      section of the HBase online manual. For more information on granting or
      revoking permissions using the AccessController, see the security
      section of the HBase online manual.
    </description>
  </property>
  <property>
    <name>hbase.procedure.regionserver.classes</name>
    <value></value>
    <description>A comma-separated list of 
    org.apache.hadoop.hbase.procedure.RegionServerProcedureManager procedure managers that are 
    loaded by default on the active HRegionServer process. The lifecycle methods (init/start/stop) 
    will be called by the active HRegionServer process to perform the specific globally barriered 
    procedure. After implementing your own RegionServerProcedureManager, just put it in 
    HBase's classpath and add the fully qualified class name here.
    </description>
  </property>
    <property>
    <name>hbase.procedure.master.classes</name>
    <value></value>
    <description>A comma-separated list of
    org.apache.hadoop.hbase.procedure.MasterProcedureManager procedure managers that are
    loaded by default on the active HMaster process. A procedure is identified by its signature and
    users can use the signature and an instant name to trigger an execution of a globally barriered
    procedure. After implementing your own MasterProcedureManager, just put it in HBase's classpath
    and add the fully qualified class name here.</description>
  </property>
  <property>
    <name>hbase.coordinated.state.manager.class</name>
    <value>org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager</value>
    <description>Fully qualified name of class implementing coordinated state manager.</description>
  </property>
  <property>
    <name>hbase.regionserver.storefile.refresh.period</name>
    <value>0</value>
    <description>
      The period (in milliseconds) for refreshing the store files for the secondary regions. 0
      means this feature is disabled. Secondary regions sees new files (from flushes and
      compactions) from primary once the secondary region refreshes the list of files in the
      region (there is no notification mechanism). But too frequent refreshes might cause
      extra Namenode pressure. If the files cannot be refreshed for longer than HFile TTL
      (hbase.master.hfilecleaner.ttl) the requests are rejected. Configuring HFile TTL to a larger
      value is also recommended with this setting.
    </description>
  </property>
  <property>
    <name>hbase.http.filter.initializers</name>
    <value>org.apache.hadoop.hbase.http.lib.StaticUserWebFilter</value>
    <description>
      类名使用逗号分割。其中的每一个类都继承自org.apache.hadoop.hbase.http.FilterInitializer。相应的过滤器将会被初始化。紧接着，过滤器在所有用户访问jsp和servlet网页的时候使用。过滤器按照定义的顺序依次使用。默认的StaticUserWebFilter过滤器会增加一个在hbase.http.staticuser.user中定义的用户。
    </description>
  </property>
    <property>
    <name>hbase.security.visibility.mutations.checkauths</name>
    <value>false</value>
    <description>
      该属性如果启用，将会检查可见表达式中的标签是否与用户发出的行为相关联。
    </description>
  </property>
  <property>
    <name>hbase.http.max.threads</name>
    <value>10</value>
    <description>
      HTTP服务器创建的线程池中线程的最大数目。
    </description>
  </property>
  <!-- Static Web User Filter properties. -->
  <property>
    <description>
      n用户名过滤器。当在静态网页上呈现内容时的过滤器。一个使用的例子是HDFS的网页UI（用于浏览文件的用户）。
    </description>
    <name>hbase.http.staticuser.user</name>
    <value>dr.stack</value>
  </property>
</configuration>
