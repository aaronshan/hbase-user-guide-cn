<?xml version="1.0"?>
<chapter
    xml:id="upgrading"
    version="5.0"
    xmlns="http://docbook.org/ns/docbook"
    xmlns:xlink="http://www.w3.org/1999/xlink"
    xmlns:xi="http://www.w3.org/2001/XInclude"
    xmlns:svg="http://www.w3.org/2000/svg"
    xmlns:m="http://www.w3.org/1998/Math/MathML"
    xmlns:html="http://www.w3.org/1999/xhtml"
    xmlns:db="http://docbook.org/ns/docbook">
    <!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
    <title>升级</title>
    <para>你不能跳过主要的版本进行升级。如果你想从0.90.x升级到0.94.x，那么你必须先从0.90.x升级到0.92.x，然后从0.92.x升级到0.94.x。</para>
    <note>
        <para>你可能会跨版本进行升级 -- 例如从0.92.2直接升级到
            0.98.0，而且还只是遵循了0.96.x的升级指导 -- 我们没有这么尝试过所以不知道升级后HBase是否能够正常工作。</para>
    </note>
    <para> 请查看 <xref
            linkend="configuration" /> 一章, 尤其是Hadoop版本那部分。 </para>
    <section
        xml:id="hbase.versioning">
        <title>HBase版本数目</title>
        <para>HBase的版本号不是线性增加的。因为源自hadoop，所以开始时的版本号和hadoop的版本对应。但是之后因为两个系统的发布频率不同，所以HBase的版本号不再与hadoop保持一致。如果你对此表示疑惑，请查看 <link
                xlink:href="http://wiki.apache.org/hadoop/Hbase/HBaseVersions">HBase
                Versioning</link> ，它将带你到HBase的版本页面。</para>
        <section
            xml:id="hbase.development.series">
            <title>奇/偶版本或者“开发”系列发行版</title>
            <para>
                未来在大的发布版之前，我们将会先发布一个预览版本以便更早的进入一个回馈周期。“开发”系列的版本的版本号总是奇数（这并非一个保证），我们不能保证两个开发序列版本之间可以进行升级（我们保留放弃“开发”系列版本之间兼容性的权利）。当然，这些开发版本都不能用于生产环境。它们只是一个预览版本，希望人们对自己感兴趣的部分进行测试，如果发现问题，及时反馈给我们。
                </para>
            <para>在HBase0.90.0之前，我们的第一个“开发”系列版本是0.89。HBase 0.95是HBase 0.96.0之前的“开发”版本。
            </para>
        </section>
        <section
            xml:id="hbase.binary.compatibility">
            <title>二进制兼容性</title>
            <para>
                当我们说两个HBase版本之间是兼容的，我们的意思是二进制兼容的。兼容的HBase版本意味着客户端可以与两个兼容但版本不同的HBase服务器进行通信。
                这也意味着你只需替换将一个版本的jar文件替换为另一个版本的jar文件，兼容的版本就可以正常工作。除非特别说明，HBase的关键版本是二进制兼容的。
                你可以安全的在两个兼容的二进制版本之间升级。例如，可以从0.94.5升级到0.94.6。
                <footnote>
                    <para>点击这里<link
                            xlink:href="http://search-hadoop.com/m/bOOvwHGW981/Does+compatibility+between+versions+also+mean+binary+compatibility%253F&amp;subj=Re+Does+compatibility+between+versions+also+mean+binary+compatibility+">版本的兼容是否也意味着二进制兼容?</link>
                        查看在hbase开发邮件列表里的讨论。 </para>
                </footnote>. </para>
        </section>
        <section
            xml:id="hbase.rolling.restart">
            <title>两个二进制兼容版本的升级</title>
            <para>除非特别说明，HBase的关键版本是二进制兼容的。你可以在两个hbase关键版本之间进行升级。例如，你可以在集群上使用0.94.6的二进制包替换0.94.5的二进制包
                来完成从0.94.5版本到0.94.6版本的升级。 </para>
        </section>
    </section>
    <section
        xml:id="upgrade1.0">
        <title>从0.98.x升级到1.0.x</title>
        <para>从0.98.x滚动升级到1.0.x版本可以工作（待做：验证！！！）。这两个版本不是二进制兼容的。</para>
        <section xml:id="upgrade1.0.changes">
            <title>变更笔记!Changes of Note!</title>
            <para>
                在这里我们列出从0.98.x到1.0.0的重要变化，你需要意识到这些变化对你升级的重要影响。
                </para>
            <section xml:id="upgrade1.0.hbase.bucketcache.percentage.in.combinedcache">
                <title>hbase.bucketcache.percentage.in.combinedcache配置已经被移除</title>
                <para>
                    如果你在使用BucketCache，你可能需要用到这个配置。如果你没有用到BucketCache，那么这个变更不会对你有所影响。它的移除意味着
                    你的 L1 LruBlockCache大小现在使用<varname>hfile.block.cache.size</varname>指定。 -- 例如，如果你没有用BucketCache你需要调整
                    onheap L1 LruBlockCache -- BucketCache的大小已经不再通过hbase.bucketcache.size来设置。你可能需要调整配置来获取在0.98.x和之前版本中设置的LruBlockCache和BucketCache的大小。
                    如果你没有在配置用设置，它的默认值是0.9。如果你什么都没做，你的BucketCache将会以10%的比例增加大小。你的L1 LruBlockCache将会变成<varname>hfile.block.cache.size</varname>乘以你的java堆大小(hfile.block.cache.size 是一个在0.0到1.0之间的浮点数)。为了阅读更多，请看<link xlink:href="https://issues.apache.org/jira/browse/HBASE-11520">HBASE-11520 通过移除令人迷惑的"hbase.bucketcache.percentage.in.combinedcache"来简化offheap缓存配置</link>。
                </para>
          </section>
        </section>
    </section>

    <section
        xml:id="upgrade0.98">
        <title>从0.96.x升级到0.98.x</title>
        <para>从0.96.x滚动升级到0.98.x可以工作。这两个版本不是二进制兼容的。</para>
        <para>需要一些额外的步骤来升级，因为0.98.x采用了一些有利的新特性，包括cell可视化标签，cell ACLs和服务器端加密传输。
            查看该指南的<xref
                    linkend="security" />章节可以获取更多信息。一个有重大影响的性能提升包括改变了预写式日志线程模型，它在高负载情况下提供更大的吞吐量，还包括
            反向索引，对快照文件的MapReduce操作以及striped合并。</para>
        <para>客户端和服务器可以运行0.98.x和0.96.x版本。但是应用可能需要重新编译，因为一些Java API已经发生了变更。</para>
    </section>
    <section>
        <title>从0.94.x升级到0.98.x</title>
        <para> 直接从0.94.x滚动升级到0.98.x会不能工作。 首先需要按照 <xref
                linkend="upgrade0.96" />进行处理。 然后再升级到0.98.x。 查看 <xref
                linkend="upgrade0.98" /> 可以得到关于0.98.x新特性的简短说明。 </para>
    </section>
    <section
        xml:id="upgrade0.96">
        <title>从0.94.x升级到0.96.x</title>
        <subtitle>不同点</subtitle>
        <para>
            你需要在升级前先关闭你的0.94.x版本的集群。如果该集群还有从集群，那么两个集群都需要进行升级。确定hbase被正确的关闭。
            留下的WAL文件越少，升级的速度将会越快（升级过程将会查找文件系统并切分日志文件）。所有的客户端也必须升级到0.96。</para>
        <para>API已经发生了改变。你需要重新使用0.96的包，将代码中的旧api使用的新api替换，并重新编译你的代码。（待做：列出这些改变） </para>
        <section>
            <title>执行0.96升级</title>
            <note>
                <para>在升级过程中，HDFS和ZooKeeper应该被关闭。</para>
            </note>
            <para>hbase-0.96.0有一个升级脚本。运行
                <programlisting language="bourne">$ bin/hbase upgrade</programlisting>来查看如何使用。这个脚本有两个主要模式：-check和-execute。</para>
            <section>
                <title>检查</title>
                <para><emphasis>检查</emphasis> 步骤针对正在运行的0.94集群。
                    在下载0.96.x二进制文件中运行它。<emphasis>检查</emphasis>步骤将查找<filename>HFileV1</filename>文件是否存在。这些文件
                    在hbase-0.96.0不被支持。为了移除它们 -- 需要将它们以HFileV2格式重写 -- 你必须运行合并操作。</para>
                <para><emphasis>检查</emphasis>步骤在它运行的末尾打印统计结果（在日志中查找“Result:”），包括发现HFileV1文件的那些被浏览的表的绝对路径，这些文件包含的region信息（这些region需要进行major合并来移除HFileV1文件），以及那些损坏的文件（如果有）。损坏的文件是不能读的，因此它们是未定义的（既不是HFileV1也不是HFileV2）。
                    </para>
                <para>为了运行检查步骤，需要运行 <command>$ bin/hbase upgrade -check</command>命令。这里有一个简单的输出：</para>
                <screen>
Tables Processed:
hdfs://localhost:41020/myHBase/.META.
hdfs://localhost:41020/myHBase/usertable
hdfs://localhost:41020/myHBase/TestTable
hdfs://localhost:41020/myHBase/t

Count of HFileV1: 2
HFileV1:
hdfs://localhost:41020/myHBase/usertable    /fa02dac1f38d03577bd0f7e666f12812/family/249450144068442524
hdfs://localhost:41020/myHBase/usertable    /ecdd3eaee2d2fcf8184ac025555bb2af/family/249450144068442512

Count of corrupted files: 1
Corrupted Files:
hdfs://localhost:41020/myHBase/usertable/fa02dac1f38d03577bd0f7e666f12812/family/1
Count of Regions with HFileV1: 2
Regions to Major Compact:
hdfs://localhost:41020/myHBase/usertable/fa02dac1f38d03577bd0f7e666f12812
hdfs://localhost:41020/myHBase/usertable/ecdd3eaee2d2fcf8184ac025555bb2af

There are some HFileV1, or corrupt files (files with incorrect major version)
                </screen>
                <para>
                    在上述简单输出中，在两个region中有两个HFileV1，还有一个损坏的文件。包含HFileV1格式的region需要进行major合并。
                    为了进行major合并，需要启动hbase shell并且学习如何合并一个独立的region。在major合并完成之后，重新运行检查命令就会发现HFileV1文件已经消失，
                    它们已经被HFileV2格式的文件取代。
                     </para>
                <para>默认情况下，检查步骤将会浏览hbase的根目录(在配置文件中由
                    hbase.rootdir定义)。为了遍历一个指定的目录，需要添加
                        <emphasis>-dir</emphasis> 选项。</para>
                <screen language="bourne">$ bin/hbase upgrade -check -dir /myHBase/testTable</screen>
                <para>上面的命令将会在/myHBase/testTable目录下检查是否含有HFileV1格式的文件。 </para>
                <para> 一旦检查步显示所有的HFileV1格式的文件已经被重写为HFileV2格式的文件，再进行升级过程就是安全的。</para>
            </section>
            <section>
                <title>执行</title>
                <para>在检查步骤显示进群已经没有HFileV1格式的文件后，进行升级过程就是安全的。接下来的是<emphasis>执行</emphasis>步骤。
                    你必须在<emphasis>执行</emphasis>步骤之前先<emphasis>关闭你的0.94.x集群</emphasis>。如果检查到HBase master或regionserver仍在运行，
                    那么执行步骤将不会运行。 <note>
                        <para>HDFS和ZooKeeper在升级之前应该先被关闭。如果zookeeper是由HBase管理的，之后你可以通过运行命令<command>$
                            ./hbase/bin/hbase-daemon.sh start zookeeper</command>来启动zookeeper。
                        </para>
                    </note>
                </para>
                <para>  <emphasis>执行</emphasis> 升级步骤由3个子步骤组成。 </para>
                <itemizedlist>
                    <listitem>
                        <para>命名空间（Namespaces）: HBase 0.96.0支持命名空间。升级需要重新对文件系统中的目录进行排序以便命名空间可以正常工作。</para>
                    </listitem>
                    <listitem>
                        <para>ZNodes: 所有的znodes应该被移除以便使用protobuf格式写入新的，并且新写入的znode应该被移动到位置。例如：replication和表状态znode。</para>
                    </listitem>
                    <listitem>
                        <para>WAL日志切分: 如果0.94.0没有被干净的(clean)关闭。将会在升级到0.96.0的过程中切分WAL日志文件。WAL切分将比本地分布式的WAL切分更慢。因为它在单一的升级进程中（因此尝试着对你的0.94.0集群进行一个干净的(clean)关闭操作）。</para>
                    </listitem>
                </itemizedlist>
                <para> 为了运行 <emphasis>执行</emphasis> 步骤，确定你已经将hbase-0.96.0的二进制文件拷贝到了所有服务器端和客户端中。确定0.94.0集群已经关闭。
                    紧接着运行：</para>
                <screen language="bourne">$ bin/hbase upgrade -execute</screen>
                <para>这里有一些简单的输出：</para>
                <programlisting>
Starting Namespace upgrade
Created version file at hdfs://localhost:41020/myHBase with version=7
Migrating table testTable to hdfs://localhost:41020/myHBase/.data/default/testTable
…..
Created version file at hdfs://localhost:41020/myHBase with version=8
Successfully completed NameSpace upgrade.
Starting Znode upgrade
….
Successfully completed Znode upgrade

Starting Log splitting
…
Successfully completed Log splitting
         </programlisting>
                <para> 如果执行步骤中的输出看起来都没问题，停止你在升级过程中启动的zookeeper：
                    <programlisting language="bourne">$ ./hbase/bin/hbase-daemon.sh stop zookeeper</programlisting>
                    现在开始使用hbase-0.96.0。 </para>
            </section>
            <section
                xml:id="s096.migration.troubleshooting">
                <title>故障排除</title>
                <section
                    xml:id="s096.migration.troubleshooting.old.client">
                    <title>旧客户端连接到0.96集群</title>
                    <para>它将会得到一个像下面展示的异常。需要进行升级。</para>
                    <screen>17:22:15  Exception in thread "main" java.lang.IllegalArgumentException: Not a host:port pair: PBUF
17:22:15  *
17:22:15   api-compat-8.ent.cloudera.com ��  ���(
17:22:15    at org.apache.hadoop.hbase.util.Addressing.parseHostname(Addressing.java:60)
17:22:15    at org.apache.hadoop.hbase.ServerName.&amp;init>(ServerName.java:101)
17:22:15    at org.apache.hadoop.hbase.ServerName.parseVersionedServerName(ServerName.java:283)
17:22:15    at org.apache.hadoop.hbase.MasterAddressTracker.bytesToServerName(MasterAddressTracker.java:77)
17:22:15    at org.apache.hadoop.hbase.MasterAddressTracker.getMasterAddress(MasterAddressTracker.java:61)
17:22:15    at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getMaster(HConnectionManager.java:703)
17:22:15    at org.apache.hadoop.hbase.client.HBaseAdmin.&amp;init>(HBaseAdmin.java:126)
17:22:15    at Client_4_3_0.setup(Client_4_3_0.java:716)
17:22:15    at Client_4_3_0.main(Client_4_3_0.java:63)</screen>
                </section>
            </section>
        </section>


    </section>

    <section
        xml:id="upgrade0.94">
        <title>从0.92.x升级到0.94.x</title>
        <para>
            我们通常认为0.92和0.94在接口上是兼容的。你可以在这两个版本之间进行升级。但是接着我们被指出
            <link
                xlink:href="https://issues.apache.org/jira/browse/HBASE-5357">HBASE-5357 Use builder
                pattern in HColumnDescriptor</link> 改变了方法签名，新的方法返回了HColumnDescriptor而不是空值。这将抛出</para>
        <screen>java.lang.NoSuchMethodError: org.apache.hadoop.hbase.HColumnDescriptor.setMaxVersions(I)V</screen>
        <para>.... 因此0.92和0.94不是完全兼容的。你不能在它们之间进行滚动升级。</para> </section>
    <section
        xml:id="upgrade0.92">
        <title>从0.90.x升级到0.92.x</title>
        <subtitle>升级指南</subtitle>
        <para>你将会发现0.92.0和0.90.x运行方式的不同。这里有一些关于从0.90.x升级到0.92.x的注意事项。</para>
        <note>
            <title>tl;dr</title>
            <para> If you've not patience, here are the important things to know upgrading. <orderedlist>
                    <listitem>
                        <para>一旦你升级了，你就不能再回退了。</para>
                    </listitem>
                    <listitem>
                        <para> 本地MemStore分配缓冲区(MemStore-Local Allocation Buffer, MSLAB)默认被启用。如果
                            你有大量的region，你需要观察堆的使用量。</para>
                    </listitem>
                    <listitem>
                        <para> 分布式日志切分默认被启用。它会使regionserver故障恢复更快速。 </para>
                    </listitem>
                    <listitem>
                        <para> 有用于安全的独立的包。 </para>
                    </listitem>
                    <listitem>
                        <para> 如果你在你的hbase-env.sh中设定了-XX:MaxDirectMemorySize，它将会启用实验性的off-heap缓存（你可能并不想这样做）。</para>
                    </listitem>
                </orderedlist>
            </para>
        </note>

        <section>
            <title>不可回退！</title>
            <para>为了升级到0.92.0，首先你需要关闭你的集群。使用hbase 0.92.0来替代你0.90.x的二进制文件（确认集群所有的机器已经被替换），然后需要重启集群（你不能从0.90.x滚动升级到0.92.x -- 你必须重启集群）。在启动后，<varname>.META.</varname> 表的内容将会被重写，从<varname>info:regioninfo</varname>列中移除表的模式。并且，启动之后的任何刷写操作将会写入
                新的0.92.0文件格式<link
                        xlink:href="http://hbase.apache.org/book.html#hfilev2">HFile V2</link>。这意味着你一旦升级到HBase 0.92.0，将会覆盖你的数据目录，也就不能再回退到0.90.x。</para>
        </section>

        <section>
            <title>默认使用MSLAB </title>
            <para>在0.92.0中，  <link
                    xlink:href="http://hbase.apache.org/book.html#hbase.hregion.memstore.mslab.enabled">hbase.hregion.memstore.mslab.enabled</link>
                标记被设置为true。 (查看 <xref
                    linkend="mslab" />)。在0.90.x它的默认值是 <constant>false</constant>。当它被启用，memstore将紧接着在内存分配给MALAB 2MB，即使
                memstore里面没有记录或者只有很少的记录。这通常是合适的，但是如果你0.90.x集群的每个regionserver有很多region（并且MSLAB被关闭），你可能发现在升级过程中会出现OOME异常。
                因为<code>thousands of regions * number of
                    column families * 2MB MSLAB (at a minimum)</code> 次put操作，将使你的堆占用达到顶峰。设置<varname>hbase.hregion.memstore.mslab.enabled</varname>
                为<constant>false</constant>或者通过设置<varname>hbase.hregion.memstore.mslab.chunksize</varname>将默认的MSLAB大小从2MB调到更低，将会避免这些错误。
            </para>
        </section>

        <section xml:id="dls">
            <title>默认使用分布式日志切分</title>
            <para>之前，WAL日志只有在宕机情况下才会被Master独立切分。在0.92.0中，regionserver的日志切分是由集群进行的（查看“HBASE-1364 [performance] Distributed
                splitting of regionserver commit logs” 或者查看博客<link xlink:href="http://blog.cloudera.com/blog/2012/07/hbase-log-splitting/">Apache HBase Log Splitting</link>）。 这将会显著减少日志切分和获取在线region的花费的时间。
            </para>
        </section>

        <section>
            <title>内存计算不同</title>
            <para>在0.92.0， <xref
                    linkend="hfilev2" /> 指标和布隆过滤器都使用了相同的LRU。这个LRU被用来缓存来自文件系统的块数据。在0.90.x中，HFile v1
                在LRU外面生存，因此它们占用空间，即使索引在一个很少使用的文件，一直不被激活使用。现在它存在于LRU中，你可能会发现块缓存空间不足。适当的调整你的块缓存。查看<xref
                        linkend="block.cache" />可以获得更多细节。块大小默认已经从从0.90.x版本的0.20（堆的20%）调整到0.25。
                 </para>
        </section>


        <section>
            <title>使用的Hadoop版本 </title>
            <para>0.92.0运行在Hadoop 1.0.x (或者CDH3u3)版本。做出升级对性能的好处是值得的。你需要一个支持工作中同步(sync)的Hadoop版本，参考 <xref
                    linkend="hadoop" />。 </para>

            <para>如果运行在 Hadoop 1.0.x (或者CDH3u3)，启用本地读。参考 <link
                    xlink:href="http://files.meetup.com/1350427/hug_ebay_jdcryans.pdf">Practical
                    Caching</link> 来查看使用本地读对性能的好处（以及如何启用本地读）。 </para>
        </section>
        <section>
            <title>HBase 0.92.0迁移到ZooKeeper 3.4.2 </title>
            <para>如果可以，升级你的zookeeper。如果不行，3.4.2版本的客户端将不能工作在3.3.x上（HBase使用了3.4.2的API）。</para>
        </section>
        <section>
            <title>在线更改默认关闭 </title>
            <para>在0.92.0中，我们加入了一个实验性的在线更改模式功能(参考 <xref
                    linkend="hbase.online.schema.update.enable" />)。它默认被关闭。你可以在你的任务中启用它。在线更改和切分表不能一起工作以便你的
                集群能静态的使用这些特性（当前）。 </para>
        </section>
        <section>
            <title>WebUI </title>
            <para>在0.92.0的web UI中加入了新的内容。它现在展示了一个当前正在进行过渡（transitioning）、最近压缩/刷写和的region列表和正在运行进程的列表（通常为空如果一切正常并且请求被及时处理）。还添加了region的请求数，一个在调试的servlet dump等。
                </para>
        </section>
        <section>
            <title>安全tarball </title>
            <para>我们有两个tarball：安全的和不安全的。文档讲述了如何设定安全的HBase。 </para>
        </section>

        <section>
            <title>HBase复制的改变 </title>
            <para>0.92.0 增加了两个新特性：多从和多主复制。启用这种方式还是通过增加一个对等的集群，因此为了配置多主集群，你只需要在主集群上运行add_peer。
                在时间戳层面的碰撞处理可能不是你想要的，这需要你在你使用情况的基础上进行评估。复制在0.92上仍处于实验阶段并且默认被禁用。如果运行它，你需要自行承担风险。
            </para>
        </section>


        <section>
            <title>现在如果OOMERegionServer将会中止 </title>
            <para>如果出现OOME异常，我们需要使用kill -9命令杀次JVM中的regionserver进程，以便它可以快速关闭。
                之前，regionserver可能在发生OOME异常之后以不正常的状态继续运行。为了禁用这种功能，推荐你在这时候关闭它，你需要编辑bin/hbase文件，
                添加-XX:OnOutOfMemoryError="kill -9 %p"参数（参考[HBASE-4769] - ‘Abort
                RegionServer Immediately on OOME’）。
                </para>
        </section>


        <section>
            <title>HFile V2和“更大，更少”的趋势 </title>
            <para>0.92.0以新的格式存储数据， <xref
                    linkend="hfilev2" />。随着HBase的运行，它将会将你所有的数据从HFile v1格式转变成HFile v2格式。
                这个自动转换随着刷写和合并操作在后台运行。HFile v2允许HBase允许更大的region/文件。事实上，我们鼓励所有的HBase使用者参考Facebook的经验，使用更大、更少的region。
                如果你现在有很多region -- 每个主机超过100个 -- 你应该设定你的region大小为更高值（0.92.0中将默认的大小从256M调整到了1G）。紧接着运行在线合并工具
                （参考“HBASE-1621 合并工具应该工作在线上集群的被禁用的表上”）。
            </para>
        </section>
    </section>
    <section
        xml:id="upgrade0.90">
        <title>从0.20.x或0.89.x升级到HBase 0.90.x</title>
        <para>
            0.90.x版本的HBase可以在HBase 0.20.x或者HBase 0.89.x的数据上启动。不需要转换数据文件。HBase 0.89.x和0.90.x写出数据到不同的region目录名中 -- 老版本用md5 hash 而不是jenkins hash来命名region -- 这意味着，一旦启动，再也不能回退到 HBase 0.20.x。 </para>
        <para>
            在升级的时候， 一定要将<filename>hbase-default.xml</filename>从你的<filename>conf</filename>目录中删掉。 0.20.x版本的配置对于0.90.x版本的HBase不是最佳的。
            <filename>hbase-default.xml</filename>现在已经被打包在HBase jar里面。如果你想看看这个文件内容，你可以在src目录下查看<filename>src/main/resources/hbase-default.xml</filename>或者参考<xref
                linkend="hbase_default_configurations" />。 </para>
        <para>
            最后，如果从0.20.x升级，需要在shell里检查.META.的模式。过去，我们推荐用户使用16KB的<varname>MEMSTORE_FLUSHSIZE</varname>。
            在shell中运行<code>hbase> scan '-ROOT-'</code>，会输出当前的<varname>.META.</varname>的模式。检查变量<varname>MEMSTORE_FLUSHSIZE</varname>
            的大小，看看是不是16kb (16384)？如果是，你需要修改它（默认值是64MB (67108864)）。运行脚本<filename>bin/set_meta_memstore_size.rb</filename>。
            这个脚本会修改.META.的模式。如果不运行的话，集群会比较慢。 <footnote>
                <para> 查看 <link
                        xlink:href="https://issues.apache.org/jira/browse/HBASE-3499">HBASE-3499
                        Users upgrading to 0.90.0 need to have their .META. table updated with the
                        right MEMSTORE_SIZE</link>
                </para>
            </footnote> 。 </para>
    </section>
</chapter>
