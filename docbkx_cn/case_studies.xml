<?xml version="1.0" encoding="UTF-8"?>
<chapter
  version="5.0"
  xml:id="casestudies"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xlink="http://www.w3.org/1999/xlink"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:svg="http://www.w3.org/2000/svg"
  xmlns:m="http://www.w3.org/1998/Math/MathML"
  xmlns:html="http://www.w3.org/1999/xhtml"
  xmlns:db="http://docbook.org/ns/docbook">
  <!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
  <title>Apache HBase 实例学习</title>
  <section
    xml:id="casestudies.overview">
    <title>概述</title>
    <para> 本章节将描述一些性能和故障诊断案例研究，这为HBase集群问题的诊断提供了一份有用的蓝本。
      </para>
    <para> 关于性能和故障诊断的更多信息，请参考 <xref
        linkend="performance" /> 和 <xref
        linkend="trouble" />。 </para>
  </section>

  <section
    xml:id="casestudies.schema">
    <title>模式设计</title>
    <para>参考：<xref
        linkend="schema.casestudies" />
    </para>

  </section>
  <!--  schema design -->

  <section
    xml:id="casestudies.perftroub">
    <title>性能/故障排除</title>

    <section
      xml:id="casestudies.slownode">
      <title>案例 #1 (单节点上的性能问题)</title>
      <section>
        <title>场景</title>
        <para> 重启后，一个数据节点表现不正常。
            针对HBase表的例行MapReduce任务往常执行完只要5到6分钟，现在开始要30或40分钟。
            最后发现这些任务都是在等待，那些分配给有问题的那个数据节点的map和reduce任务（例如，运行慢的map任务都有同样的Input Split）。
            这种情况在分布式拷贝期间会到紧要关头，由于这个滞后的节点，复制过程会严重拖延。
          </para>
      </section>
      <section>
        <title>硬件</title>
        <itemizedlist>
          <title>数据节点:</title>
          <listitem>
            <para>2个 12-核 处理器</para>
          </listitem>
          <listitem>
            <para>6个 Enerprise SATA 硬盘</para>
          </listitem>
          <listitem>
            <para>24GB内存</para>
          </listitem>
          <listitem>
            <para>两个粘合的千兆级网卡</para>
          </listitem>
        </itemizedlist>
        <itemizedlist>
          <title>网络:</title>
          <listitem>
            <para>10千兆级架顶交换机</para>
          </listitem>
          <listitem>
            <para>20 千兆级机架连接线</para>
          </listitem>
        </itemizedlist>
      </section>
      <section>
        <title>假设</title>
        <section>
          <title>HBase “热点” Region</title>
          <para> 我们假设正在经历一个熟悉的痛点：HBase表中的一个“热点”，key空间分配不均匀会造成大量的请求打到
              一个单独的region上，会“轰击”RegionServer进程并导致缓慢的响应时间。对HBase Master状态页的检查表明
              问题节点的请求数基本为0。而且，对HBase日志的检查表明没有region分裂，压缩或有其它region在进行转换（transition）。
              这有力的排除了“热点”是响应缓慢的根本原因。


          </para>
        </section>
        <section>
          <title>HBase Region和非本地数据</title>
          <para> 我们的下一个假设是，有一个MapReduce任务正在从HBase请求数据，但该HBase对于datanode来说不是本地的，
             因此HDFS不得不通过网络从其它服务器上请求数据块。检查datanode日志表明通过网络请求的数据块特别少，这表明
            HBase region分配得很正确，大部分必要的数据位于节点上。这也派出了非本地数据导致响应缓慢的可能性。

           </para>
        </section>
        <section>
          <title>过度工作或有问题的磁盘，或内存交换造成I/O等待过多</title>
          <para>以上结论表明 Hadoop和HBase不像是罪魁祸首，我们继续对datanode的硬件进行故障排除。
            JAVA，在设计上，将定期扫描它的整个内存空间以进行垃圾收集。如果系统内存使用过量，Linux内核会进入一个恶性循环，
            它将耗尽所有资源来交换回java堆内存，从磁盘到RAM，因为java要运行垃圾收集程序。此外，一个有问题的硬盘在放弃或返回一个错误之前，
            会重试读/写多次。这就变现出很高的iowait，因为正在运行的进程需要等待读写操作完成。最后，一个快接近性能上限的磁盘也会导致io等待，
            因为它会告诉内核，它无法再接收更多的数据了，内核就会将到来的数据列入到内存中的脏写池中。
            </para>
        </section>
        <section>
          <title>处理器高使用造成的缓慢</title>
          <para> 接下来，我们会检查，看看系统运行缓慢是否只是因为计算负载太高。
              <code>top(1)</code>表明系统负载比正常时候要高，但<code>vmstat(1)</code> 和 <code>mpstat(1)</code>
              表明用于实际计算的处理器数比较少。
         </para>
        </section>
        <section>
          <title>网络饱和(赢家)</title>
          <para> 既然不是磁盘也不是处理器被过度使用，那么我们接着看看网络设备的性能。
            datanode有2个千兆级以太网适配器，结合成主备模式的接口。 <code>ifconfig(8)</code>显示有
              一些不寻常的异常，超量，帧错误。虽然不是闻所未闻，但对于现在的硬件上的操作来说，出现这些错误是非常罕见的：
 </para>
          <screen language="bourne">		
$ /sbin/ifconfig bond0
bond0  Link encap:Ethernet  HWaddr 00:00:00:00:00:00  
inet addr:10.x.x.x  Bcast:10.x.x.255  Mask:255.255.255.0
UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1
RX packets:2990700159 errors:12 dropped:0 overruns:1 frame:6          &lt;--- Look Here! Errors!
TX packets:3443518196 errors:0 dropped:0 overruns:0 carrier:0
collisions:0 txqueuelen:0 
RX bytes:2416328868676 (2.4 TB)  TX bytes:3464991094001 (3.4 TB)
        </screen>
          <para>
              这些错误立即让我们怀疑,一个或多个以太网接口可能协商出错误的线路速度。
              通过下面两点证实了这个怀疑：从一个外部主机运行ICMP ping并观察超过700 ms的往返时间，
              在结合的接口成员上运行 <code>ethtool(8)</code>，并发现活动接口以100mb/s，全双工运行。
           </para>
          <screen language="bourne">		
$ sudo ethtool eth0
Settings for eth0:
Supported ports: [ TP ]
Supported link modes:   10baseT/Half 10baseT/Full 
                       100baseT/Half 100baseT/Full 
                       1000baseT/Full 
Supports auto-negotiation: Yes
Advertised link modes:  10baseT/Half 10baseT/Full 
                       100baseT/Half 100baseT/Full 
                       1000baseT/Full 
Advertised pause frame use: No
Advertised auto-negotiation: Yes
Link partner advertised link modes:  Not reported
Link partner advertised pause frame use: No
Link partner advertised auto-negotiation: No
Speed: 100Mb/s                                     &lt;--- Look Here!  Should say 1000Mb/s!
Duplex: Full
Port: Twisted Pair
PHYAD: 1
Transceiver: internal
Auto-negotiation: on
MDI-X: Unknown
Supports Wake-on: umbg
Wake-on: g
Current message level: 0x00000003 (3)
Link detected: yes
          </screen>
          <para>在正常操作中，ICMP ping 往返时间应该在20ms左右， 接口速度和双工应该分别为"1000MB/s"和"Full"。
               </para>
        </section>
      </section>
      <section>
        <title>解决方案</title>
        <para>
            确定活动的以太网适配器速度不正确后，我们使用了 <code>ifenslave(8)</code> 命令使备用接口成为活动接口，
            这立即改善了MapReduce性能，使网络吞吐量提高了10倍。  </para>
          <para>
            接着在数据中心，我们最终确定线路速度的问题是由一根坏网络电缆造成的，然后更换了它。

        </para>
      </section>
    </section>
    <!--  case study -->
    <section
      xml:id="casestudies.perf.1">
        <title>案例#2(性能研究 2012)</title>
      <para>  一个自称“我们不知道怎么了，但似乎很慢”的问题的调查结果。 <link
          xlink:href="http://gbif.blogspot.com/2012/03/hbase-performance-evaluation-continued.html">http://gbif.blogspot.com/2012/03/hbase-performance-evaluation-continued.html</link>
      </para>
    </section>

    <section
      xml:id="casestudies.perf.2">
      <title> 案例#3(性能研究 2010)</title>
      <para>  2010年的对于一般集群的性能的调查结果。尽管这项研究基于一个旧版本的代码库，这篇文章在方法层面仍然非常有用。 <link
          xlink:href="http://hstack.org/hbase-performance-testing/">http://hstack.org/hbase-performance-testing/</link>
      </para>
    </section>

    <section
      xml:id="casestudies.max.transfer.threads">
      <title>案例#4(max.transfer.threads配置)</title>
      <para>   配置<code>max.transfer.threads</code> (以前为xcievers)及 诊断来自于错误配置的错误。<link
          xlink:href="http://www.larsgeorge.com/2012/03/hadoop-hbase-and-xceivers.html">http://www.larsgeorge.com/2012/03/hadoop-hbase-and-xceivers.html</link>
      </para>
      <para> 参考 <xref
          linkend="dfs.datanode.max.transfer.threads" />。 </para>
    </section>

  </section>
  <!--  performance/troubleshooting -->

</chapter>
